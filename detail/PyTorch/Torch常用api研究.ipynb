{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运算用设备： mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#####检测可使用的运算设备#####\n",
    "if torch.cuda.is_available():\n",
    "    CHIP=\"cuda\"   #Nvidia - Compute Unified Device Architecture\n",
    "elif torch.backends.mps.is_built():\n",
    "    CHIP=\"mps\"    #Apple Silicon - API Metal - Metal Performance Shaders\n",
    "else:\n",
    "    CHIP=\"cpu\"\n",
    "device = torch.device(CHIP)\n",
    "print(\"运算用设备：\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 torch 向量(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each torch.Tensor has a torch.dtype, torch.device, and torch.layout.\n",
    "\n",
    "requires_grad:\n",
    "\n",
    "- 在用户手动定义tensor时，参数requires_grad默认值是False。\n",
    "\n",
    "- 而在Module中的层在定义时，相关tensor的requires_grad参数默认是True。\n",
    "\n",
    "- 在计算图中，如果有一个输入的requires_grad是True，那么输出的requires_grad也是True。只有在所有输入的requires_grad都为False时，输出的requires_grad才为False。\n",
    "\n",
    "backward():\n",
    "\n",
    "- 只能对标量求导数（梯度）\n",
    "\n",
    "\n",
    "detach():\n",
    "\n",
    "- 返回一个新的tensor，并且这个tensor是从当前的计算图中分离出来的（截断计算图）。但是返回的tensor和原来的tensor是共享内存空间的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([2, 4, 6], dtype=torch.float, device=device, requires_grad=True)\n",
    "c=torch.tensor([1,2,3], dtype=torch.float, device=device, requires_grad=True)\n",
    "print(a.grad)\n",
    "print(a.size())\n",
    "\n",
    "b=3*a*a+2*c*c*c\n",
    "b1=b.sum()\n",
    "\n",
    "print(b)\n",
    "print(b1)\n",
    "b1.backward()\n",
    "\n",
    "print('梯度：',a.grad)\n",
    "print('梯度：',c.grad)\n",
    "\n",
    "print(a.is_leaf)\n",
    "print(c.is_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变形：\n",
    "\n",
    "❌  view() （已过时）\n",
    "\n",
    "✅  reshape()\n",
    "\n",
    "- reshape方法更强大，可以认为a.reshape = a.view() + a.contiguous().view()。\n",
    "\n",
    "- https://blog.csdn.net/Flag_ing/article/details/109129752"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 基础网络 torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 线性层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "CLASS torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Linear_Layer=nn.Linear(2,3,bias=False,device=device)\n",
    "\n",
    "a=torch.randn(5,2).to(device)\n",
    "b=A_Linear_Layer(a)\n",
    "\n",
    "print(a)\n",
    "print(list(A_Linear_Layer.named_parameters()))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 其他基础层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "池化层\n",
    "\n",
    "``` python\n",
    "CLASS torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "```\n",
    "\n",
    "(N,C,H,W) 批量大小，通道数，图片高度，图片宽度\n",
    "\n",
    "kernel_size ：表示做最大池化的窗口大小，可以是单个值，也可以是tuple元组\n",
    "\n",
    "stride ：步长，可以是单个值，也可以是tuple元组\n",
    "\n",
    "padding ：填充，可以是单个值，也可以是tuple元组\n",
    "\n",
    "dilation ：控制窗口中元素步幅\n",
    "\n",
    "return_indices ：布尔类型，返回最大值位置索引\n",
    "\n",
    "ceil_mode ：布尔类型，为True，用向上取整的方法，计算输出形状；默认是向下取整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn((1,3,8,8),requires_grad=True)\n",
    "Pooling_Layer=nn.MaxPool2d((4,4),return_indices=True)\n",
    "b=Pooling_Layer(a)\n",
    "\n",
    "list(b)[0].backward(torch.ones_like(list(b)[0])) #b.backward(torch.ones(1,3,2,2))\n",
    "\n",
    "print(a)\n",
    "print(list(b)[0])\n",
    "print(a.grad[0][0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化层\n",
    "\n",
    "``` python\n",
    "CLASS torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)\n",
    "```\n",
    "\n",
    "num_features：一般输入参数为batch_size×num_features×height×width，即为其中特征的数量\n",
    "\n",
    "eps：分母中添加的一个值，目的是为了计算的稳定性，默认为：1e-5\n",
    "\n",
    "momentum：一个用于运行过程中均值和方差的一个估计参数（我的理解是一个稳定系数，类似于SGD中的momentum的系数）\n",
    "\n",
    "affine：当设为true时，会给定可以学习的系数矩阵gamma和beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "```\n",
    "\n",
    "groups:分组，输入、输出通道均分组，均需被其整除\n",
    "\n",
    "![卷积层groups](./pic/卷积层groups.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn((1,3,8,8),requires_grad=True,device=device)\n",
    "Conv_Layer=nn.Conv2d(3,2,(4,4),device=device)\n",
    "b=Conv_Layer(a)\n",
    "\n",
    "b.backward(torch.ones_like(b))\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 循环层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.LSTM\n",
    "\n",
    "初始化：\n",
    "\n",
    "``` python\n",
    "CLASS torch.nn.LSTM(*args, **kwargs)\n",
    "```\n",
    "![LSTM参数](pic/LSTM参数.png)\n",
    "\n",
    "- input_size – The number of expected features in the input x\n",
    "- hidden_size – The number of features in the hidden state h\n",
    "- num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and - computing the final results. Default: 1\n",
    "- bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "- batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the - Inputs/Outputs sections below for details. Default: False\n",
    "- dropout – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "- bidirectional – If True, becomes a bidirectional LSTM. Default: False\n",
    "- proj_size – If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "\n",
    "输入：input, (h_0, c_0)\n",
    "- input: (L,H_in)  (L,N,H_in)or(N,L,H_in) depending on batch_first\n",
    "- h_0:   (D*num_layers,H_out)   (D*num_layers,N,H_out)\n",
    "- c_0:   (D*num_layers,H_cell)   (D*num_layers,N,H_cell)\n",
    "\n",
    "N=batch size       L=sequence length         D=2 if 双向 else 1\n",
    "\n",
    "输出：output, (h_n, c_n)\n",
    "- output: (L,D*H_out)         (L,N,D*H_out)or(N,L,D*H_out)\n",
    "- h_n:   (D*num_layers,H_out)    (D*num_layers,N,H_out)\n",
    "- c_n:   (D*num_layers,H_cell)   (D*num_layers,N,H_cell)\n",
    "\n",
    "- H_in=input size\n",
    "- H_cell=hidden size\n",
    "- H_out=hidden size  OR  proj_size if it>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter  #试用tensorboard\n",
    "#writer = SummaryWriter('./log')\n",
    "\n",
    "BATCH=3\n",
    "\n",
    "rnn = nn.LSTM(5, 7, 2).to(device)\n",
    "input = torch.randn((4, BATCH, 5),device=device)\n",
    "h0 = torch.randn((2, BATCH, 7),device=device)\n",
    "c0 = torch.randn((2, BATCH, 7),device=device)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "print(input)\n",
    "print(output)\n",
    "\n",
    "output.backward(torch.ones_like(output))\n",
    "print(type(rnn.named_parameters()))\n",
    "print(list(rnn.named_parameters()))\n",
    "\n",
    "#writer.add_scalar(\"output\", output[0][0][0], 1)\n",
    "\n",
    "#torch.onnx.export(rnn,input,'rnn.onnx',export_params=True,opset_version=8,) #BATCH调为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Transformer层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入x：\n",
      "tensor([[[1.2518e-01, 7.6708e-01, 9.9076e-01, 9.6356e-01, 6.7897e-02],\n",
      "         [3.9633e-01, 8.0347e-01, 8.4013e-02, 9.0199e-01, 3.1302e-01],\n",
      "         [1.1181e-01, 7.9944e-01, 6.7452e-01, 9.3328e-01, 6.3262e-02],\n",
      "         [2.0702e-01, 6.8050e-01, 3.9385e-01, 8.1455e-01, 3.5479e-01]],\n",
      "\n",
      "        [[4.4721e-01, 9.4178e-01, 7.0384e-01, 1.5469e-01, 5.3296e-02],\n",
      "         [3.1771e-01, 2.6059e-01, 1.1724e-01, 9.5483e-01, 7.5291e-01],\n",
      "         [9.8392e-01, 9.0223e-02, 5.2201e-01, 7.5489e-01, 4.1476e-01],\n",
      "         [5.9577e-01, 3.5304e-02, 4.0942e-01, 6.5249e-01, 2.2043e-01]],\n",
      "\n",
      "        [[6.0339e-01, 2.2344e-01, 8.3389e-01, 8.6196e-02, 5.6590e-01],\n",
      "         [1.7142e-01, 2.7986e-01, 9.1285e-01, 4.6759e-01, 1.2341e-01],\n",
      "         [7.5597e-01, 9.1207e-01, 8.7149e-02, 6.0758e-01, 6.6533e-01],\n",
      "         [5.3542e-01, 9.4108e-01, 7.2428e-01, 7.0315e-01, 3.0422e-01]],\n",
      "\n",
      "        [[8.5563e-01, 4.1562e-01, 9.7038e-01, 6.9138e-01, 5.4039e-01],\n",
      "         [3.8641e-01, 5.2206e-01, 2.0135e-01, 5.4041e-01, 2.0157e-01],\n",
      "         [7.7002e-01, 6.8036e-01, 6.1097e-01, 8.2866e-01, 1.6795e-01],\n",
      "         [3.9299e-01, 3.2626e-01, 8.6020e-02, 8.2189e-01, 9.2320e-01]],\n",
      "\n",
      "        [[4.8097e-01, 4.2999e-01, 1.0286e-01, 2.0255e-01, 7.4155e-01],\n",
      "         [7.4179e-02, 9.2452e-01, 3.0976e-01, 4.7477e-02, 3.8149e-01],\n",
      "         [5.5798e-01, 8.7828e-01, 2.0402e-01, 9.0168e-01, 1.8456e-01],\n",
      "         [1.6194e-01, 8.3114e-01, 5.5446e-01, 3.6865e-01, 2.3177e-01]],\n",
      "\n",
      "        [[2.6965e-01, 9.4985e-01, 6.6646e-01, 9.4167e-01, 6.3159e-01],\n",
      "         [5.9790e-01, 1.3664e-01, 7.7255e-01, 1.3974e-01, 7.8380e-01],\n",
      "         [5.0001e-01, 2.3817e-01, 5.9920e-01, 4.3354e-01, 2.6752e-01],\n",
      "         [3.2234e-01, 3.8113e-02, 4.0068e-01, 3.6267e-01, 1.1566e-01]],\n",
      "\n",
      "        [[8.8694e-02, 9.4638e-01, 9.2629e-01, 7.3805e-02, 6.1675e-01],\n",
      "         [7.1596e-01, 4.2508e-01, 7.5648e-01, 9.3082e-01, 2.4228e-01],\n",
      "         [8.9989e-01, 1.9097e-01, 6.7639e-01, 7.8550e-01, 7.2792e-01],\n",
      "         [3.5821e-01, 4.5146e-01, 7.7690e-01, 5.0940e-01, 4.2031e-01]],\n",
      "\n",
      "        [[6.6378e-01, 8.9330e-01, 9.5568e-01, 9.4857e-01, 8.9577e-01],\n",
      "         [3.4428e-01, 8.6698e-01, 5.8240e-01, 2.7147e-01, 3.6182e-01],\n",
      "         [5.9110e-01, 7.3409e-01, 7.1258e-01, 5.0226e-01, 7.6866e-01],\n",
      "         [4.8219e-01, 5.7639e-02, 1.8774e-01, 5.3208e-01, 6.9922e-02]],\n",
      "\n",
      "        [[1.4618e-01, 1.0536e-02, 8.5473e-04, 4.7866e-01, 5.3143e-01],\n",
      "         [8.8777e-02, 1.9941e-01, 1.2827e-01, 5.4178e-01, 6.5562e-01],\n",
      "         [3.1793e-01, 6.8146e-01, 9.0255e-01, 7.9728e-01, 5.1057e-01],\n",
      "         [7.9521e-01, 8.2425e-01, 1.0063e-01, 8.4288e-01, 8.3701e-01]],\n",
      "\n",
      "        [[1.4522e-01, 9.1738e-02, 6.9882e-01, 5.3209e-01, 7.2961e-01],\n",
      "         [1.4140e-01, 3.5909e-01, 7.6295e-01, 9.0745e-01, 3.4270e-01],\n",
      "         [8.4604e-01, 7.1596e-01, 2.2184e-01, 9.8135e-01, 7.4663e-01],\n",
      "         [6.8993e-01, 1.4619e-01, 5.0273e-01, 1.6444e-01, 7.9303e-01]],\n",
      "\n",
      "        [[5.2870e-02, 2.3466e-01, 5.5443e-01, 4.9559e-01, 4.1302e-01],\n",
      "         [7.4740e-01, 5.3907e-02, 5.0944e-01, 5.9536e-01, 7.1778e-01],\n",
      "         [9.4257e-01, 6.3196e-02, 1.6955e-01, 7.4504e-01, 2.5719e-01],\n",
      "         [2.1761e-03, 5.8307e-01, 7.5430e-01, 2.9688e-01, 8.0108e-01]],\n",
      "\n",
      "        [[1.6951e-01, 4.3511e-01, 9.1111e-01, 6.4461e-01, 8.3256e-01],\n",
      "         [9.4133e-01, 4.2678e-01, 3.4403e-01, 4.7686e-01, 4.1155e-01],\n",
      "         [4.5813e-01, 2.5715e-01, 3.2693e-01, 7.3140e-01, 9.6676e-01],\n",
      "         [8.4904e-01, 3.8342e-01, 8.6998e-01, 8.1007e-01, 5.2079e-01]],\n",
      "\n",
      "        [[2.6963e-01, 4.2357e-01, 8.2968e-01, 8.0474e-01, 7.1432e-01],\n",
      "         [4.7567e-01, 9.7069e-01, 4.0523e-01, 4.5501e-01, 5.0156e-01],\n",
      "         [8.9225e-01, 3.4055e-01, 6.3103e-01, 6.4553e-01, 3.0714e-01],\n",
      "         [9.6893e-01, 7.2157e-01, 4.2752e-01, 1.5827e-01, 4.5748e-01]],\n",
      "\n",
      "        [[8.3103e-01, 4.2687e-01, 5.2491e-01, 8.1275e-02, 4.3927e-01],\n",
      "         [1.2710e-01, 4.3249e-01, 8.0929e-01, 8.2673e-01, 2.0521e-01],\n",
      "         [6.9446e-02, 3.2955e-01, 4.6332e-01, 9.3835e-01, 2.2157e-01],\n",
      "         [1.7152e-01, 9.1002e-01, 4.7087e-01, 6.6796e-01, 9.4844e-01]],\n",
      "\n",
      "        [[2.5397e-02, 4.5245e-02, 3.4355e-01, 2.9563e-01, 2.9487e-01],\n",
      "         [5.4650e-01, 1.6866e-01, 5.6255e-01, 1.7151e-01, 8.4577e-01],\n",
      "         [1.6434e-01, 8.3207e-01, 5.2335e-02, 8.6020e-02, 4.2578e-01],\n",
      "         [9.7563e-01, 2.3730e-01, 3.0760e-01, 5.7123e-01, 1.4960e-01]],\n",
      "\n",
      "        [[6.7294e-01, 8.4971e-01, 9.2132e-01, 1.1462e-01, 9.3664e-01],\n",
      "         [3.1412e-01, 9.1016e-01, 7.9327e-01, 3.7605e-01, 8.2946e-01],\n",
      "         [3.6476e-02, 9.1332e-01, 2.4034e-01, 3.6808e-01, 5.2079e-01],\n",
      "         [9.4659e-01, 3.7055e-01, 8.2604e-01, 2.0904e-01, 4.9538e-01]],\n",
      "\n",
      "        [[5.4713e-01, 1.0621e-01, 5.5229e-01, 6.8683e-01, 5.3819e-01],\n",
      "         [5.6464e-01, 2.7161e-01, 9.9844e-01, 1.1167e-01, 1.3760e-01],\n",
      "         [4.3422e-01, 9.1784e-01, 4.1461e-01, 7.5890e-01, 2.0843e-01],\n",
      "         [4.1935e-01, 8.3272e-01, 8.4781e-01, 5.3595e-01, 5.1756e-01]],\n",
      "\n",
      "        [[4.4039e-01, 2.5575e-01, 2.8143e-01, 3.8661e-01, 3.6796e-01],\n",
      "         [1.5535e-01, 7.6897e-01, 6.7007e-01, 4.8056e-01, 5.1007e-01],\n",
      "         [4.8994e-01, 2.1816e-01, 2.0521e-01, 9.4646e-01, 9.0810e-01],\n",
      "         [2.3224e-01, 4.1121e-01, 2.1657e-01, 3.0661e-01, 4.3608e-01]],\n",
      "\n",
      "        [[8.7532e-01, 8.1022e-01, 2.3464e-01, 1.3286e-02, 1.4543e-01],\n",
      "         [9.8349e-01, 9.3882e-01, 6.6828e-01, 7.1943e-01, 1.7080e-01],\n",
      "         [2.3766e-01, 1.9543e-01, 7.9160e-01, 9.5626e-01, 9.2493e-01],\n",
      "         [5.7509e-01, 2.5405e-01, 4.6556e-01, 9.0530e-01, 6.8962e-01]],\n",
      "\n",
      "        [[5.3932e-01, 8.0062e-01, 4.9556e-02, 7.7656e-01, 6.6442e-01],\n",
      "         [1.1520e-01, 3.9150e-01, 2.2011e-01, 3.5021e-01, 2.4238e-01],\n",
      "         [3.9541e-01, 6.9825e-01, 7.1909e-01, 4.6910e-02, 2.1190e-01],\n",
      "         [5.7288e-01, 7.4085e-01, 1.2256e-01, 1.2196e-01, 9.6695e-01]]])\n",
      "输入y（标注）：\n",
      "tensor([[[0.1184, 0.9485, 0.8610, 0.4234, 0.0939],\n",
      "         [0.0913, 0.3087, 0.9453, 0.7223, 0.0870],\n",
      "         [0.2573, 0.5292, 0.9289, 0.9516, 0.0416],\n",
      "         [0.3693, 0.7605, 0.7954, 0.7314, 0.0204]],\n",
      "\n",
      "        [[0.2908, 0.3261, 0.6618, 0.1884, 0.4712],\n",
      "         [0.6331, 0.0260, 0.7724, 0.8256, 0.7087],\n",
      "         [0.1364, 0.9330, 0.9411, 0.1488, 0.9735],\n",
      "         [0.9166, 0.2514, 0.9342, 0.4621, 0.9918]],\n",
      "\n",
      "        [[0.2984, 0.8607, 0.4783, 0.6901, 0.8509],\n",
      "         [0.1622, 0.2440, 0.9214, 0.6269, 0.2354],\n",
      "         [0.8093, 0.8207, 0.3634, 0.5171, 0.5571],\n",
      "         [0.9440, 0.8297, 0.1209, 0.2432, 0.0611]],\n",
      "\n",
      "        [[0.5577, 0.9567, 0.6601, 0.7312, 0.9648],\n",
      "         [0.0103, 0.5215, 0.9642, 0.4415, 0.1470],\n",
      "         [0.1089, 0.6147, 0.6755, 0.2345, 0.9393],\n",
      "         [0.3099, 0.2270, 0.9213, 0.4249, 0.0382]],\n",
      "\n",
      "        [[0.3290, 0.8213, 0.5466, 0.3681, 0.1818],\n",
      "         [0.5138, 0.6071, 0.8749, 0.0211, 0.5735],\n",
      "         [0.2076, 0.9861, 0.5447, 0.1840, 0.2940],\n",
      "         [0.5368, 0.8691, 0.1901, 0.3105, 0.7480]],\n",
      "\n",
      "        [[0.8585, 0.7911, 0.2043, 0.5933, 0.2611],\n",
      "         [0.5396, 0.2129, 0.0567, 0.0499, 0.6573],\n",
      "         [0.5255, 0.3254, 0.7463, 0.3035, 0.9980],\n",
      "         [0.5846, 0.8449, 0.7119, 0.6545, 0.0322]],\n",
      "\n",
      "        [[0.8827, 0.4812, 0.2110, 0.5417, 0.5741],\n",
      "         [0.5384, 0.2720, 0.9554, 0.5164, 0.4884],\n",
      "         [0.1448, 0.7935, 0.6983, 0.8284, 0.3649],\n",
      "         [0.3938, 0.8811, 0.7636, 0.6556, 0.3557]],\n",
      "\n",
      "        [[0.6742, 0.5695, 0.1175, 0.8690, 0.2631],\n",
      "         [0.2313, 0.2416, 0.8675, 0.7031, 0.0147],\n",
      "         [0.7477, 0.6833, 0.4923, 0.2594, 0.7515],\n",
      "         [0.9371, 0.6861, 0.9960, 0.6379, 0.8114]],\n",
      "\n",
      "        [[0.1000, 0.4090, 0.8282, 0.3356, 0.8896],\n",
      "         [0.8882, 0.1037, 0.7793, 0.4459, 0.8211],\n",
      "         [0.7423, 0.5406, 0.8770, 0.7354, 0.1103],\n",
      "         [0.4492, 0.5960, 0.3370, 0.9325, 0.0041]],\n",
      "\n",
      "        [[0.2322, 0.1640, 0.3980, 0.1782, 0.1059],\n",
      "         [0.4975, 0.4113, 0.1431, 0.3408, 0.7899],\n",
      "         [0.6999, 0.1658, 0.0164, 0.0932, 0.3508],\n",
      "         [0.8516, 0.2311, 0.0386, 0.1306, 0.2301]],\n",
      "\n",
      "        [[0.4565, 0.4807, 0.3934, 0.2704, 0.6530],\n",
      "         [0.6067, 0.7537, 0.3691, 0.4005, 0.9892],\n",
      "         [0.6600, 0.6985, 0.9971, 0.8869, 0.2199],\n",
      "         [0.1860, 0.1157, 0.5540, 0.6260, 0.1426]],\n",
      "\n",
      "        [[0.8917, 0.0434, 0.1721, 0.3930, 0.4027],\n",
      "         [0.8954, 0.1735, 0.1938, 0.8122, 0.0317],\n",
      "         [0.7124, 0.5493, 0.2999, 0.7916, 0.7515],\n",
      "         [0.0415, 0.4072, 0.1431, 0.7123, 0.7736]],\n",
      "\n",
      "        [[0.3293, 0.6497, 0.7399, 0.1196, 0.0024],\n",
      "         [0.5429, 0.1528, 0.0179, 0.0668, 0.9959],\n",
      "         [0.8408, 0.7828, 0.1995, 0.0697, 0.4289],\n",
      "         [0.5520, 0.9336, 0.8909, 0.9333, 0.9644]],\n",
      "\n",
      "        [[0.3411, 0.6857, 0.2094, 0.3579, 0.8818],\n",
      "         [0.5309, 0.2045, 0.2578, 0.7757, 0.4090],\n",
      "         [0.9278, 0.2611, 0.4250, 0.1896, 0.9968],\n",
      "         [0.9663, 0.0103, 0.0038, 0.1792, 0.9367]],\n",
      "\n",
      "        [[0.3494, 0.1860, 0.6662, 0.1594, 0.5204],\n",
      "         [0.6210, 0.6367, 0.9955, 0.1691, 0.3333],\n",
      "         [0.0047, 0.8108, 0.7827, 0.6567, 0.4636],\n",
      "         [0.4586, 0.5922, 0.3836, 0.8763, 0.8039]],\n",
      "\n",
      "        [[0.4974, 0.7788, 0.1270, 0.2456, 0.3929],\n",
      "         [0.1574, 0.5581, 0.1485, 0.1280, 0.2133],\n",
      "         [0.1720, 0.1439, 0.9028, 0.5306, 0.3960],\n",
      "         [0.3614, 0.2196, 0.6818, 0.0963, 0.7108]],\n",
      "\n",
      "        [[0.6731, 0.5146, 0.0349, 0.5886, 0.7332],\n",
      "         [0.0607, 0.8827, 0.4239, 0.6802, 0.9633],\n",
      "         [0.6146, 0.5381, 0.1703, 0.9765, 0.1973],\n",
      "         [0.9998, 0.9552, 0.5679, 0.1091, 0.5140]],\n",
      "\n",
      "        [[0.3678, 0.4138, 0.2515, 0.5712, 0.3169],\n",
      "         [0.9408, 0.1041, 0.3958, 0.7058, 0.6130],\n",
      "         [0.3364, 0.1336, 0.7021, 0.3741, 0.1505],\n",
      "         [0.8299, 0.4802, 0.7426, 0.3884, 0.5328]],\n",
      "\n",
      "        [[0.9607, 0.0099, 0.5855, 0.9591, 0.2432],\n",
      "         [0.3100, 0.0383, 0.6415, 0.3731, 0.6514],\n",
      "         [0.0907, 0.0137, 0.8725, 0.9195, 0.2294],\n",
      "         [0.0657, 0.3496, 0.7048, 0.6722, 0.7265]],\n",
      "\n",
      "        [[0.8159, 0.8799, 0.0166, 0.2221, 0.0066],\n",
      "         [0.7175, 0.5366, 0.1867, 0.1548, 0.7290],\n",
      "         [0.7213, 0.9721, 0.2746, 0.6225, 0.7040],\n",
      "         [0.7010, 0.7861, 0.5165, 0.1099, 0.5035]],\n",
      "\n",
      "        [[0.8988, 0.0121, 0.8460, 0.0784, 0.0437],\n",
      "         [0.6159, 0.5206, 0.9472, 0.0178, 0.0607],\n",
      "         [0.6301, 0.7203, 0.5892, 0.2297, 0.3097],\n",
      "         [0.6512, 0.4075, 0.0834, 0.7410, 0.4937]],\n",
      "\n",
      "        [[0.2191, 0.0950, 0.3728, 0.5705, 0.4848],\n",
      "         [0.4794, 0.6343, 0.3480, 0.1177, 0.8014],\n",
      "         [0.6915, 0.8616, 0.5100, 0.6283, 0.8403],\n",
      "         [0.2778, 0.2081, 0.4457, 0.5947, 0.0678]],\n",
      "\n",
      "        [[0.3708, 0.6316, 0.3547, 0.1624, 0.5212],\n",
      "         [0.9092, 0.2837, 0.7833, 0.9213, 0.4140],\n",
      "         [0.0658, 0.2350, 0.1898, 0.6534, 0.3234],\n",
      "         [0.7616, 0.7412, 0.4897, 0.6940, 0.5674]],\n",
      "\n",
      "        [[0.5045, 0.1165, 0.0892, 0.3706, 0.6434],\n",
      "         [0.5996, 0.2343, 0.0195, 0.7049, 0.1774],\n",
      "         [0.9432, 0.4540, 0.7286, 0.9345, 0.8315],\n",
      "         [0.3544, 0.1981, 0.0047, 0.9600, 0.2077]],\n",
      "\n",
      "        [[0.1646, 0.4056, 0.4962, 0.8213, 0.6079],\n",
      "         [0.9756, 0.6046, 0.3642, 0.7146, 0.8035],\n",
      "         [0.0296, 0.8168, 0.0513, 0.6097, 0.7706],\n",
      "         [0.6330, 0.7620, 0.4937, 0.8338, 0.5456]],\n",
      "\n",
      "        [[0.0206, 0.4723, 0.1435, 0.5592, 0.7821],\n",
      "         [0.4899, 0.6349, 0.3011, 0.6873, 0.9558],\n",
      "         [0.7683, 0.3738, 0.4765, 0.9834, 0.9208],\n",
      "         [0.4564, 0.4272, 0.0355, 0.4973, 0.0479]],\n",
      "\n",
      "        [[0.4019, 0.2523, 0.5847, 0.8153, 0.1089],\n",
      "         [0.2801, 0.3402, 0.9891, 0.6342, 0.1182],\n",
      "         [0.6466, 0.4603, 0.5085, 0.2429, 0.2681],\n",
      "         [0.8904, 0.7596, 0.1207, 0.1710, 0.8894]],\n",
      "\n",
      "        [[0.8542, 0.6050, 0.7441, 0.5264, 0.2619],\n",
      "         [0.1345, 0.3691, 0.7771, 0.3316, 0.6260],\n",
      "         [0.7450, 0.5174, 0.4558, 0.7620, 0.6510],\n",
      "         [0.5072, 0.4947, 0.5597, 0.8596, 0.6318]],\n",
      "\n",
      "        [[0.2122, 0.6999, 0.1688, 0.5962, 0.1169],\n",
      "         [0.4077, 0.6987, 0.8498, 0.5680, 0.7992],\n",
      "         [0.6608, 0.3202, 0.3191, 0.4360, 0.6352],\n",
      "         [0.0368, 0.0136, 0.5069, 0.9820, 0.2740]],\n",
      "\n",
      "        [[0.5387, 0.6652, 0.2207, 0.9669, 0.8106],\n",
      "         [0.7529, 0.2508, 0.8182, 0.8345, 0.6681],\n",
      "         [0.0868, 0.2169, 0.2135, 0.8685, 0.1805],\n",
      "         [0.2804, 0.1960, 0.0899, 0.0332, 0.3187]]])\n",
      "输出y（预测）：\n",
      "tensor([[[ 0.3363, -0.9340,  1.8070, -0.5097, -0.6996],\n",
      "         [ 0.0825, -1.0246,  1.8715, -0.5319, -0.3975],\n",
      "         [-0.2214, -0.8050,  1.9118, -0.0851, -0.8003],\n",
      "         [ 0.5898, -1.1521,  1.4051,  0.2841, -1.1269]],\n",
      "\n",
      "        [[-0.2438, -1.4055,  1.3558, -0.5894,  0.8829],\n",
      "         [-0.1400, -1.0039,  1.9156, -0.3344, -0.4372],\n",
      "         [ 0.3288, -0.5134,  1.8157, -0.8391, -0.7921],\n",
      "         [-0.0241, -1.2939,  1.2969, -0.8958,  0.9170]],\n",
      "\n",
      "        [[-0.7811, -0.7340,  1.2720, -0.9281,  1.1712],\n",
      "         [-0.0437, -1.0667,  1.8552, -0.1069, -0.6379],\n",
      "         [ 0.2029, -0.8739,  1.4583, -1.3313,  0.5440],\n",
      "         [ 1.7731, -0.6712,  0.1543, -1.1726, -0.0836]],\n",
      "\n",
      "        [[-0.1347, -1.4528,  1.6659, -0.2548,  0.1763],\n",
      "         [ 0.0872, -1.0741,  1.8510, -0.5718, -0.2923],\n",
      "         [-0.4389, -0.9873,  1.9255, -0.2665, -0.2328],\n",
      "         [ 0.3251, -1.2015,  1.7443, -0.5594, -0.3085]],\n",
      "\n",
      "        [[ 1.8899, -0.0746, -0.2817, -1.0562, -0.4773],\n",
      "         [ 0.4478, -0.6273,  1.6119, -1.3415, -0.0910],\n",
      "         [-0.2200, -0.8921,  1.8101, -0.9128,  0.2148],\n",
      "         [ 1.0603, -1.0965,  0.8867, -1.2986,  0.4481]],\n",
      "\n",
      "        [[ 1.1054, -1.5061,  0.5331, -0.8462,  0.7138],\n",
      "         [ 0.3865, -1.1030,  1.6524, -0.9504,  0.0145],\n",
      "         [ 0.1800, -0.9747,  1.7792, -0.9208, -0.0637],\n",
      "         [ 0.5496, -1.4847,  1.5229, -0.3220, -0.2659]],\n",
      "\n",
      "        [[ 0.6851, -1.8393,  0.7577, -0.2992,  0.6957],\n",
      "         [-0.4785, -0.4683,  1.9243, -0.9195, -0.0579],\n",
      "         [-0.1824, -0.8193,  1.8533, -0.9249,  0.0733],\n",
      "         [ 0.7794, -0.4585,  1.1599, -1.6733,  0.1924]],\n",
      "\n",
      "        [[ 1.2991, -0.7537, -1.4723,  0.1924,  0.7345],\n",
      "         [-0.3896, -0.1372,  1.7427, -1.3336,  0.1176],\n",
      "         [-0.3166, -0.7000,  1.9359, -0.8057, -0.1135],\n",
      "         [-0.0389, -1.6761,  1.3770, -0.1742,  0.5123]],\n",
      "\n",
      "        [[ 0.5786, -1.7360,  0.9673, -0.4957,  0.6857],\n",
      "         [-0.1233, -0.6065,  1.9607, -0.7026, -0.5284],\n",
      "         [ 0.4463, -0.9593,  1.7426, -0.8242, -0.4054],\n",
      "         [ 0.9139, -1.6021,  0.8645,  0.5581, -0.7344]],\n",
      "\n",
      "        [[ 0.0407, -1.4947,  1.6422,  0.0636, -0.2518],\n",
      "         [-0.0106, -0.7590,  1.9276, -0.4418, -0.7162],\n",
      "         [ 0.2129, -0.9702,  1.8469, -0.6110, -0.4786],\n",
      "         [ 1.0044, -1.6694,  1.0066, -0.4283,  0.0866]],\n",
      "\n",
      "        [[ 0.6945, -1.3073,  0.9216, -1.1321,  0.8232],\n",
      "         [ 0.5115, -1.0285,  1.7134, -0.4778, -0.7186],\n",
      "         [-0.4546, -0.9925,  1.8912,  0.0357, -0.4798],\n",
      "         [-0.2634, -1.4766,  1.5866, -0.2558,  0.4092]],\n",
      "\n",
      "        [[ 0.9040, -1.7213,  0.9395, -0.4672,  0.3449],\n",
      "         [ 0.3315, -1.1607,  1.6900, -0.8280, -0.0328],\n",
      "         [ 0.4957, -1.6436,  1.0320, -0.6425,  0.7583],\n",
      "         [ 0.3986, -1.4694,  1.1933, -0.8520,  0.7295]],\n",
      "\n",
      "        [[ 0.8370, -1.6282,  1.1931, -0.4692,  0.0673],\n",
      "         [ 0.2496, -0.3822,  1.7405, -1.2884, -0.3195],\n",
      "         [-0.6205, -0.4412,  1.7502, -1.0926,  0.4042],\n",
      "         [ 0.0073, -0.9552,  1.5773, -1.1518,  0.5223]],\n",
      "\n",
      "        [[ 0.3258, -1.2636,  1.1396, -1.0954,  0.8936],\n",
      "         [ 0.2807, -1.0988,  1.6632, -0.9659,  0.1208],\n",
      "         [-0.3639, -0.8562,  1.9511, -0.5397, -0.1913],\n",
      "         [ 0.6634, -0.8756,  1.2912, -1.4181,  0.3391]],\n",
      "\n",
      "        [[ 0.3636, -1.7377,  1.2247, -0.3358,  0.4853],\n",
      "         [-0.5556, -0.5363,  1.9963, -0.5213, -0.3831],\n",
      "         [-0.2264,  0.5296,  1.6265, -0.6813, -1.2485],\n",
      "         [-1.0072, -1.2354,  1.3674,  0.1162,  0.7590]],\n",
      "\n",
      "        [[-0.0369, -1.3765,  1.6318, -0.5659,  0.3475],\n",
      "         [-0.1913, -0.7222,  1.9530, -0.7288, -0.3107],\n",
      "         [-0.0443, -1.1447,  1.8589, -0.2720, -0.3979],\n",
      "         [ 0.7093, -1.3919,  1.3716, -0.8139,  0.1249]],\n",
      "\n",
      "        [[ 0.8604, -1.1955, -0.3504, -0.7692,  1.4546],\n",
      "         [-0.5085, -0.3467,  1.9838, -0.7205, -0.4081],\n",
      "         [-0.5557, -1.5112,  1.4907,  0.1901,  0.3861],\n",
      "         [ 1.1393, -1.2334,  1.0366, -1.0466,  0.1041]],\n",
      "\n",
      "        [[ 0.4733, -1.9221,  0.9595,  0.3883,  0.1009],\n",
      "         [ 0.1477, -0.7546,  1.7837, -1.1054, -0.0715],\n",
      "         [ 0.0208, -1.1539,  1.8266, -0.1335, -0.5600],\n",
      "         [-0.0636, -1.3751,  1.7308, -0.3286,  0.0364]],\n",
      "\n",
      "        [[ 0.9331, -1.8073,  0.2924, -0.2606,  0.8424],\n",
      "         [ 0.0408, -0.8717,  1.8784, -0.8079, -0.2395],\n",
      "         [-0.0295, -1.2963,  1.7622,  0.0248, -0.4613],\n",
      "         [ 0.1729, -1.5217,  1.5483, -0.4442,  0.2447]],\n",
      "\n",
      "        [[ 1.9189, -0.3330, -0.9919, -0.4495, -0.1446],\n",
      "         [ 0.0447, -1.0257,  1.8721, -0.5941, -0.2969],\n",
      "         [-0.2939, -0.5822,  1.6811, -1.2465,  0.4415],\n",
      "         [ 1.0185, -1.1893,  1.3402, -0.7694, -0.4000]],\n",
      "\n",
      "        [[-0.5436, -1.2727,  1.7558,  0.0227,  0.0379],\n",
      "         [ 0.4051, -0.8251,  1.5761, -1.2862,  0.1301],\n",
      "         [-0.0338, -0.4712,  1.9283, -0.5607, -0.8626],\n",
      "         [ 0.5530, -1.8335,  1.1506,  0.0659,  0.0640]],\n",
      "\n",
      "        [[ 0.5396, -1.5898,  1.3930,  0.1303, -0.4732],\n",
      "         [ 0.3565, -0.8074,  1.5966, -1.2855,  0.1398],\n",
      "         [-0.0687, -0.9853,  1.9097, -0.5030, -0.3527],\n",
      "         [ 0.0799, -1.6492,  1.5042,  0.1000, -0.0349]],\n",
      "\n",
      "        [[ 0.9325, -0.8738, -0.3058, -1.1498,  1.3969],\n",
      "         [-0.6505, -0.5328,  1.9812, -0.5559, -0.2420],\n",
      "         [-0.7769, -0.9287,  1.8459, -0.3116,  0.1714],\n",
      "         [ 0.4081, -1.3701,  1.6136, -0.5904, -0.0612]],\n",
      "\n",
      "        [[ 0.6859, -1.8250,  0.6674, -0.3309,  0.8025],\n",
      "         [ 0.4981, -0.9465,  1.6368, -1.0794, -0.1090],\n",
      "         [ 0.2979, -1.4390,  1.6356, -0.1006, -0.3939],\n",
      "         [ 0.6106, -1.9218,  0.7999, -0.0301,  0.5414]],\n",
      "\n",
      "        [[ 0.2552, -1.5235,  1.1161, -0.7475,  0.8997],\n",
      "         [ 0.3059, -1.4391,  1.6432, -0.3058, -0.2043],\n",
      "         [-0.0690, -1.0255,  1.5738, -1.0619,  0.5826],\n",
      "         [ 0.7103, -1.2702,  1.2105, -1.1015,  0.4510]],\n",
      "\n",
      "        [[ 0.1777, -1.8049,  1.1716, -0.1143,  0.5699],\n",
      "         [ 0.0082, -0.9174,  1.8778, -0.7699, -0.1986],\n",
      "         [ 1.3096, -1.3802,  0.7443, -0.8841,  0.2103],\n",
      "         [ 1.4079, -1.2153,  0.6968, -1.0190,  0.1297]],\n",
      "\n",
      "        [[-0.5162, -1.6187,  1.3063,  0.5928,  0.2357],\n",
      "         [ 0.2153, -0.7494,  1.7367, -1.1725, -0.0301],\n",
      "         [-0.4947, -1.0056,  1.8998, -0.3657, -0.0339],\n",
      "         [ 0.8041, -1.7163,  0.8345, -0.5563,  0.6340]],\n",
      "\n",
      "        [[ 0.1562, -1.3197,  1.6169,  0.2816, -0.7351],\n",
      "         [ 0.0457, -0.9836,  1.8672, -0.7014, -0.2279],\n",
      "         [ 0.1021, -1.1397,  1.8350, -0.3456, -0.4519],\n",
      "         [ 0.7290, -1.1083,  0.4234, -1.2590,  1.2149]],\n",
      "\n",
      "        [[ 1.3530, -1.0477,  0.6388,  0.3082, -1.2524],\n",
      "         [-0.0681, -0.6067,  1.9514, -0.6842, -0.5924],\n",
      "         [-0.5810, -0.2697,  1.8619, -1.0586,  0.0474],\n",
      "         [-0.4946, -1.4503,  1.6076,  0.0948,  0.2425]],\n",
      "\n",
      "        [[ 0.3600, -1.4768, -0.6854,  0.3553,  1.4469],\n",
      "         [ 0.0748, -1.0789,  1.8477, -0.5955, -0.2482],\n",
      "         [-0.3466, -1.5948,  1.2967,  0.7953, -0.1507],\n",
      "         [-0.0261, -1.1766,  1.3686, -1.0125,  0.8466]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "[('encoder.layers.0.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.3041,  0.1062, -0.5404, -0.1622, -0.5080],\n",
      "        [-0.3810,  0.0567,  0.5024,  0.0395, -0.2462],\n",
      "        [-0.4506, -0.4718,  0.1524, -0.5035,  0.3526],\n",
      "        [ 0.2180,  0.1192,  0.2745, -0.1689, -0.2921],\n",
      "        [ 0.4007,  0.0402, -0.4855,  0.0731, -0.0889],\n",
      "        [ 0.4845,  0.3557,  0.5297,  0.3191, -0.2001],\n",
      "        [-0.2348,  0.4491, -0.2430, -0.0792,  0.2755],\n",
      "        [-0.1719,  0.1605,  0.1389, -0.0513,  0.1591],\n",
      "        [ 0.2177,  0.3385,  0.1227, -0.0965, -0.1182],\n",
      "        [-0.2733,  0.4887,  0.3255, -0.2480, -0.0207],\n",
      "        [-0.4921, -0.2381,  0.0073, -0.4388, -0.0041],\n",
      "        [ 0.3276, -0.4684,  0.0988,  0.2354,  0.2664],\n",
      "        [ 0.4746, -0.4289, -0.5341, -0.0383, -0.4238],\n",
      "        [ 0.1525,  0.4333,  0.1196,  0.2607,  0.4545],\n",
      "        [ 0.2822, -0.4300, -0.3016, -0.2200, -0.1510]], requires_grad=True)), ('encoder.layers.0.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.0.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.0030, -0.2299,  0.7452,  0.4546, -0.3118],\n",
      "        [-0.4975, -0.2192,  0.4797,  0.4956,  0.7106],\n",
      "        [-0.4631,  0.3335, -0.6898, -0.2137,  0.4113],\n",
      "        [-0.5558,  0.0344,  0.2974, -0.0240,  0.4438],\n",
      "        [-0.6039,  0.1846, -0.1012,  0.2202,  0.4481]], requires_grad=True)), ('encoder.layers.0.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.0.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0092,  0.0406, -0.0411,  0.0245, -0.0101],\n",
      "        [-0.0431, -0.0197,  0.0521,  0.0187,  0.0385],\n",
      "        [ 0.0367,  0.0217,  0.0475, -0.0493,  0.0192],\n",
      "        ...,\n",
      "        [ 0.0396, -0.0195, -0.0222,  0.0427, -0.0194],\n",
      "        [ 0.0205, -0.0172,  0.0491,  0.0421, -0.0325],\n",
      "        [-0.0431,  0.0362, -0.0399, -0.0261, -0.0183]], requires_grad=True)), ('encoder.layers.0.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.0.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0381, -0.0187, -0.0531,  ..., -0.0343, -0.0091,  0.0393],\n",
      "        [-0.0539,  0.0329, -0.0050,  ..., -0.0521,  0.0145, -0.0153],\n",
      "        [ 0.0223,  0.0203,  0.0192,  ...,  0.0163,  0.0248, -0.0351],\n",
      "        [-0.0268, -0.0323,  0.0281,  ...,  0.0053,  0.0295,  0.0434],\n",
      "        [ 0.0109,  0.0023,  0.0334,  ...,  0.0246, -0.0410,  0.0283]],\n",
      "       requires_grad=True)), ('encoder.layers.0.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.0.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.0.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.0.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.0.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.1.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.4393,  0.3641, -0.2143,  0.3153,  0.0055],\n",
      "        [ 0.3931,  0.0596,  0.0084, -0.2833, -0.5370],\n",
      "        [ 0.1884,  0.0448, -0.1712,  0.4842, -0.0149],\n",
      "        [-0.2257, -0.2725, -0.2750,  0.4342, -0.1528],\n",
      "        [ 0.4306, -0.3624,  0.1552, -0.4733,  0.1759],\n",
      "        [ 0.0608, -0.3539, -0.1161,  0.0987, -0.5112],\n",
      "        [ 0.1850, -0.3159,  0.3661,  0.3772,  0.0841],\n",
      "        [-0.0446,  0.4698, -0.4491, -0.5200,  0.0878],\n",
      "        [-0.2844, -0.1763,  0.3035, -0.1909, -0.3184],\n",
      "        [ 0.2434, -0.1498,  0.4087, -0.3171, -0.2491],\n",
      "        [ 0.4324,  0.1443, -0.4378, -0.2572, -0.0231],\n",
      "        [ 0.2632, -0.2929, -0.2238, -0.5131,  0.3420],\n",
      "        [ 0.2414, -0.2462,  0.3483,  0.1658, -0.0474],\n",
      "        [-0.5218, -0.3336, -0.4169, -0.1002, -0.3493],\n",
      "        [ 0.1604, -0.2629,  0.0941, -0.4276,  0.4769]], requires_grad=True)), ('encoder.layers.1.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.1.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.3710, -0.4459,  0.4961,  0.4540, -0.1717],\n",
      "        [ 0.3347,  0.3418, -0.7444, -0.0878,  0.3176],\n",
      "        [-0.7136, -0.6680,  0.2777, -0.1391,  0.3135],\n",
      "        [ 0.5415,  0.7657, -0.7558, -0.5816,  0.7416],\n",
      "        [-0.6878,  0.4560, -0.4301, -0.0893, -0.2997]], requires_grad=True)), ('encoder.layers.1.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.1.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0315, -0.0190,  0.0150, -0.0469, -0.0179],\n",
      "        [ 0.0141,  0.0340, -0.0285, -0.0393, -0.0215],\n",
      "        [-0.0122,  0.0069,  0.0320, -0.0153,  0.0262],\n",
      "        ...,\n",
      "        [ 0.0465,  0.0424,  0.0270,  0.0181, -0.0182],\n",
      "        [ 0.0406, -0.0149, -0.0520, -0.0437,  0.0191],\n",
      "        [ 0.0158, -0.0484, -0.0511, -0.0517, -0.0024]], requires_grad=True)), ('encoder.layers.1.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.1.linear2.weight', Parameter containing:\n",
      "tensor([[-0.0158,  0.0405, -0.0472,  ...,  0.0386,  0.0280,  0.0187],\n",
      "        [ 0.0490,  0.0496, -0.0105,  ...,  0.0161, -0.0350,  0.0506],\n",
      "        [ 0.0240,  0.0264, -0.0147,  ...,  0.0066, -0.0410,  0.0446],\n",
      "        [-0.0073, -0.0042, -0.0435,  ...,  0.0269,  0.0366,  0.0250],\n",
      "        [ 0.0105, -0.0391,  0.0374,  ...,  0.0159,  0.0355,  0.0141]],\n",
      "       requires_grad=True)), ('encoder.layers.1.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.1.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.1.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.1.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.1.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.2.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.4045,  0.1714,  0.1578, -0.0051,  0.3933],\n",
      "        [ 0.2222, -0.0013,  0.1949, -0.2338,  0.3692],\n",
      "        [-0.0622, -0.3837, -0.3214,  0.2219, -0.1463],\n",
      "        [-0.3866, -0.4292,  0.4033,  0.3931,  0.2115],\n",
      "        [ 0.0139, -0.0726, -0.2790,  0.3840,  0.2174],\n",
      "        [-0.4963, -0.0179,  0.3704,  0.1799, -0.0587],\n",
      "        [-0.1388, -0.3664,  0.4256, -0.0945, -0.4252],\n",
      "        [-0.0260, -0.0975, -0.2565, -0.1208, -0.3882],\n",
      "        [-0.4327, -0.2935, -0.0763,  0.5057, -0.4565],\n",
      "        [ 0.4496, -0.4896,  0.4280,  0.3642,  0.4703],\n",
      "        [-0.0988,  0.4298, -0.0646, -0.3882,  0.3221],\n",
      "        [-0.5182, -0.0764, -0.0365, -0.4471, -0.1932],\n",
      "        [ 0.2967, -0.2714, -0.4669, -0.4305,  0.4780],\n",
      "        [ 0.0045, -0.2304,  0.3705, -0.4132,  0.3554],\n",
      "        [ 0.4958, -0.0708, -0.0661,  0.2390,  0.3821]], requires_grad=True)), ('encoder.layers.2.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.2.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.1730,  0.2284, -0.6752,  0.5277, -0.6811],\n",
      "        [ 0.6497, -0.4366,  0.3250,  0.7379, -0.1324],\n",
      "        [ 0.4895,  0.6633, -0.4355,  0.1988, -0.7343],\n",
      "        [-0.3587, -0.4709, -0.2470,  0.7273,  0.4605],\n",
      "        [-0.3218, -0.1562,  0.3480,  0.2496,  0.5031]], requires_grad=True)), ('encoder.layers.2.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.2.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0093,  0.0437, -0.0066, -0.0436, -0.0321],\n",
      "        [-0.0144,  0.0047,  0.0415, -0.0409, -0.0352],\n",
      "        [ 0.0359, -0.0284,  0.0125,  0.0172, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0407, -0.0531,  0.0192, -0.0002],\n",
      "        [-0.0523,  0.0057, -0.0334, -0.0451, -0.0152],\n",
      "        [-0.0042,  0.0425,  0.0119,  0.0441, -0.0465]], requires_grad=True)), ('encoder.layers.2.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.2.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0494, -0.0311,  0.0086,  ..., -0.0406,  0.0388, -0.0029],\n",
      "        [-0.0053, -0.0379,  0.0025,  ..., -0.0308, -0.0055, -0.0042],\n",
      "        [-0.0259, -0.0032,  0.0345,  ...,  0.0310, -0.0112, -0.0130],\n",
      "        [ 0.0103,  0.0036, -0.0178,  ..., -0.0447,  0.0404,  0.0050],\n",
      "        [ 0.0111,  0.0329, -0.0110,  ...,  0.0270, -0.0112, -0.0081]],\n",
      "       requires_grad=True)), ('encoder.layers.2.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.2.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.2.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.2.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.2.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.3.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.3705,  0.2765,  0.0212,  0.2817, -0.2730],\n",
      "        [-0.0628, -0.4286,  0.2471, -0.1698,  0.5106],\n",
      "        [ 0.2942,  0.1564,  0.3380, -0.2104,  0.3111],\n",
      "        [-0.0511,  0.3060, -0.4875, -0.0661, -0.2794],\n",
      "        [ 0.0381,  0.0017,  0.4239, -0.0493,  0.0681],\n",
      "        [-0.2775, -0.2292,  0.3564,  0.0055, -0.1103],\n",
      "        [-0.2955,  0.0616,  0.3706,  0.2227,  0.4914],\n",
      "        [ 0.0739, -0.3776,  0.5128,  0.2887,  0.3313],\n",
      "        [-0.5170,  0.1335,  0.0009, -0.4962, -0.1639],\n",
      "        [-0.3912,  0.1571, -0.4637, -0.4842,  0.1981],\n",
      "        [-0.3698,  0.2284,  0.1170, -0.5147,  0.5000],\n",
      "        [ 0.3947, -0.1370,  0.3380,  0.4764, -0.3539],\n",
      "        [-0.1583,  0.1576, -0.0958,  0.4554, -0.2308],\n",
      "        [ 0.5388,  0.5018, -0.0735,  0.0267,  0.3002],\n",
      "        [ 0.2106,  0.2807,  0.5273,  0.3347, -0.4904]], requires_grad=True)), ('encoder.layers.3.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.3.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.6639, -0.2537, -0.6675, -0.7664,  0.6303],\n",
      "        [-0.0629,  0.1596, -0.0303,  0.4684,  0.2201],\n",
      "        [-0.5803, -0.2498,  0.0072,  0.1111,  0.3732],\n",
      "        [-0.0112,  0.0042, -0.7417,  0.1218, -0.0706],\n",
      "        [ 0.3775,  0.4277,  0.0119, -0.0936, -0.6911]], requires_grad=True)), ('encoder.layers.3.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.3.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0031,  0.0493,  0.0008, -0.0350,  0.0235],\n",
      "        [ 0.0422, -0.0413, -0.0524,  0.0208,  0.0092],\n",
      "        [-0.0322,  0.0397,  0.0037,  0.0467,  0.0357],\n",
      "        ...,\n",
      "        [ 0.0274,  0.0317, -0.0151, -0.0396,  0.0313],\n",
      "        [-0.0481, -0.0329, -0.0303,  0.0215, -0.0339],\n",
      "        [-0.0180,  0.0313,  0.0458,  0.0534, -0.0290]], requires_grad=True)), ('encoder.layers.3.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.3.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0530,  0.0378, -0.0460,  ..., -0.0258, -0.0066,  0.0271],\n",
      "        [-0.0119, -0.0114,  0.0341,  ..., -0.0041,  0.0333, -0.0498],\n",
      "        [ 0.0248, -0.0422, -0.0178,  ...,  0.0363, -0.0031,  0.0165],\n",
      "        [-0.0330,  0.0168,  0.0045,  ..., -0.0022, -0.0375,  0.0202],\n",
      "        [ 0.0278, -0.0348, -0.0169,  ..., -0.0534,  0.0084,  0.0241]],\n",
      "       requires_grad=True)), ('encoder.layers.3.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.3.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.3.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.3.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.3.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.4.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.0022, -0.5137, -0.1671, -0.3785, -0.2074],\n",
      "        [-0.4170, -0.4566, -0.1650,  0.3570, -0.4361],\n",
      "        [-0.0077, -0.2531,  0.4938,  0.2831, -0.3498],\n",
      "        [ 0.5366, -0.2853,  0.3133,  0.0940,  0.1589],\n",
      "        [ 0.3290,  0.0588,  0.3576, -0.3530, -0.1073],\n",
      "        [-0.2874, -0.2023,  0.0542, -0.0358, -0.3484],\n",
      "        [ 0.1702, -0.0169,  0.3353,  0.3771, -0.5072],\n",
      "        [ 0.2675,  0.0935,  0.4378, -0.5440, -0.0756],\n",
      "        [-0.0604, -0.5273, -0.3747, -0.1529,  0.3039],\n",
      "        [ 0.0093,  0.3015, -0.0376, -0.0722, -0.4978],\n",
      "        [ 0.3979,  0.4046,  0.2821,  0.3360, -0.2508],\n",
      "        [-0.2269,  0.3898, -0.0479,  0.2811,  0.1829],\n",
      "        [-0.4231, -0.3745,  0.4645, -0.4931,  0.4151],\n",
      "        [ 0.1166, -0.2955, -0.0538,  0.3829,  0.0244],\n",
      "        [-0.4038, -0.0657, -0.0141,  0.4970,  0.4339]], requires_grad=True)), ('encoder.layers.4.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.4.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.4957,  0.5620,  0.5259,  0.7180, -0.3668],\n",
      "        [ 0.1620,  0.6576, -0.4925, -0.0698,  0.4061],\n",
      "        [-0.0759,  0.1150, -0.7628, -0.0435,  0.2135],\n",
      "        [-0.4427, -0.5798,  0.5031, -0.2464,  0.0255],\n",
      "        [ 0.5865, -0.5517, -0.1243,  0.4600,  0.3281]], requires_grad=True)), ('encoder.layers.4.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.4.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0238, -0.0324,  0.0258, -0.0426,  0.0222],\n",
      "        [-0.0036,  0.0187,  0.0001, -0.0523, -0.0161],\n",
      "        [ 0.0515,  0.0005,  0.0377, -0.0212,  0.0018],\n",
      "        ...,\n",
      "        [ 0.0349,  0.0540, -0.0139,  0.0319, -0.0292],\n",
      "        [-0.0031, -0.0020, -0.0288, -0.0079, -0.0148],\n",
      "        [ 0.0268,  0.0351, -0.0337, -0.0460, -0.0442]], requires_grad=True)), ('encoder.layers.4.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.4.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0033, -0.0258, -0.0427,  ...,  0.0248, -0.0433, -0.0080],\n",
      "        [ 0.0270,  0.0488, -0.0275,  ...,  0.0414, -0.0170,  0.0184],\n",
      "        [-0.0101, -0.0144, -0.0031,  ...,  0.0084,  0.0095,  0.0307],\n",
      "        [ 0.0297,  0.0421,  0.0331,  ..., -0.0130, -0.0216, -0.0091],\n",
      "        [ 0.0219,  0.0505,  0.0271,  ..., -0.0439,  0.0175, -0.0078]],\n",
      "       requires_grad=True)), ('encoder.layers.4.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.4.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.4.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.4.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.4.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.5.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.0393,  0.3935,  0.2386,  0.1875, -0.2190],\n",
      "        [-0.1216, -0.1171, -0.5123,  0.3183,  0.4981],\n",
      "        [-0.0562, -0.2019,  0.0922, -0.3794, -0.5260],\n",
      "        [ 0.3561,  0.4820,  0.3796, -0.2083, -0.3741],\n",
      "        [-0.4589,  0.3060,  0.4189, -0.4381,  0.2428],\n",
      "        [-0.4433, -0.0674, -0.4698, -0.0867,  0.4604],\n",
      "        [-0.4304,  0.1908, -0.1858,  0.0770,  0.1159],\n",
      "        [ 0.3522,  0.3515,  0.1463, -0.1569,  0.4176],\n",
      "        [-0.3705, -0.1666, -0.0880, -0.2500,  0.0427],\n",
      "        [-0.2343, -0.4045, -0.0328,  0.3185, -0.2039],\n",
      "        [ 0.0099, -0.0711, -0.1438, -0.3533, -0.3755],\n",
      "        [ 0.4694,  0.1217,  0.3699, -0.0422, -0.0697],\n",
      "        [-0.2448,  0.4406,  0.2008, -0.4132,  0.3040],\n",
      "        [ 0.1852,  0.1394, -0.5459, -0.0059, -0.1352],\n",
      "        [-0.0839,  0.1196,  0.2373,  0.4148, -0.4650]], requires_grad=True)), ('encoder.layers.5.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.5.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.0596, -0.5634,  0.2270, -0.6947, -0.1428],\n",
      "        [-0.7119,  0.1095, -0.5838,  0.4970, -0.0460],\n",
      "        [-0.3941, -0.0200,  0.2461,  0.5554,  0.4417],\n",
      "        [ 0.2625, -0.4713,  0.2640, -0.4286,  0.4286],\n",
      "        [-0.1233,  0.3421,  0.1678, -0.6766, -0.7512]], requires_grad=True)), ('encoder.layers.5.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.5.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0474, -0.0494, -0.0399, -0.0029,  0.0393],\n",
      "        [ 0.0045,  0.0319,  0.0005, -0.0422, -0.0225],\n",
      "        [-0.0396, -0.0297, -0.0236,  0.0066, -0.0334],\n",
      "        ...,\n",
      "        [ 0.0012,  0.0126,  0.0313,  0.0258,  0.0483],\n",
      "        [ 0.0092, -0.0089, -0.0454,  0.0329, -0.0446],\n",
      "        [ 0.0213,  0.0537,  0.0041,  0.0513,  0.0358]], requires_grad=True)), ('encoder.layers.5.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.5.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0275, -0.0423,  0.0163,  ..., -0.0213,  0.0462, -0.0219],\n",
      "        [-0.0432, -0.0265, -0.0333,  ..., -0.0021, -0.0009,  0.0136],\n",
      "        [-0.0173,  0.0150,  0.0276,  ...,  0.0308, -0.0493,  0.0135],\n",
      "        [ 0.0423, -0.0086,  0.0047,  ..., -0.0258, -0.0247,  0.0170],\n",
      "        [-0.0007,  0.0404,  0.0088,  ...,  0.0272, -0.0266, -0.0514]],\n",
      "       requires_grad=True)), ('encoder.layers.5.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.5.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.5.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.5.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.5.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.6.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.1288, -0.2531, -0.3643, -0.3781, -0.0610],\n",
      "        [-0.2694,  0.3463,  0.4109, -0.0681, -0.1642],\n",
      "        [-0.3865, -0.0213,  0.0842, -0.2263, -0.3219],\n",
      "        [-0.4155, -0.1734,  0.3904,  0.2267,  0.1455],\n",
      "        [-0.2342, -0.5388, -0.5171,  0.1074,  0.4498],\n",
      "        [ 0.5436, -0.4038,  0.0146, -0.4126, -0.3124],\n",
      "        [-0.3253,  0.5467,  0.0677, -0.1155, -0.2643],\n",
      "        [-0.1067, -0.4335,  0.1268,  0.1903,  0.4009],\n",
      "        [ 0.5408,  0.0226, -0.2334,  0.0680,  0.1714],\n",
      "        [ 0.0192, -0.4543,  0.3411,  0.1621,  0.4603],\n",
      "        [-0.3764,  0.0860,  0.0221,  0.5112, -0.0549],\n",
      "        [-0.0387, -0.1044,  0.4874,  0.0200, -0.3935],\n",
      "        [-0.4807,  0.1777,  0.2462,  0.4881,  0.3942],\n",
      "        [ 0.2934,  0.0424,  0.3961,  0.4681, -0.0803],\n",
      "        [ 0.1908, -0.4672, -0.0832,  0.3407,  0.4686]], requires_grad=True)), ('encoder.layers.6.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.6.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.3455, -0.6107,  0.1856,  0.3108,  0.3762],\n",
      "        [ 0.5692, -0.6847, -0.5325,  0.5310, -0.1178],\n",
      "        [ 0.1029,  0.6660,  0.6539, -0.0642, -0.7169],\n",
      "        [ 0.7090,  0.4180,  0.6382,  0.7157,  0.3530],\n",
      "        [ 0.3528,  0.5932, -0.5846, -0.0121, -0.0828]], requires_grad=True)), ('encoder.layers.6.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.6.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0473, -0.0533,  0.0176,  0.0397,  0.0297],\n",
      "        [-0.0274, -0.0280,  0.0081, -0.0418, -0.0262],\n",
      "        [ 0.0371,  0.0167, -0.0509, -0.0363, -0.0524],\n",
      "        ...,\n",
      "        [ 0.0281,  0.0395, -0.0520, -0.0203,  0.0024],\n",
      "        [ 0.0081,  0.0053, -0.0087,  0.0390,  0.0472],\n",
      "        [ 0.0162, -0.0530, -0.0071,  0.0088,  0.0260]], requires_grad=True)), ('encoder.layers.6.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.6.linear2.weight', Parameter containing:\n",
      "tensor([[ 2.7630e-02, -2.1710e-02,  1.6663e-02,  ...,  3.3199e-02,\n",
      "          2.0342e-03, -4.2712e-02],\n",
      "        [ 4.6559e-02, -3.6069e-02,  2.8761e-02,  ..., -3.9253e-05,\n",
      "         -4.5864e-03, -1.6883e-02],\n",
      "        [ 1.1625e-02, -5.6574e-03, -6.1388e-03,  ...,  4.5620e-02,\n",
      "          3.0056e-02, -3.2405e-02],\n",
      "        [ 1.7648e-02, -1.7173e-02, -2.7422e-02,  ...,  4.2445e-02,\n",
      "          3.3951e-02,  1.9964e-02],\n",
      "        [ 3.4260e-02, -5.1298e-02, -5.1082e-02,  ..., -3.7525e-02,\n",
      "         -4.7631e-02,  4.1439e-02]], requires_grad=True)), ('encoder.layers.6.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.6.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.6.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.6.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.6.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.7.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 4.8851e-01, -5.1180e-01,  1.5904e-01, -4.4404e-01, -8.5480e-03],\n",
      "        [-2.9304e-01, -5.0064e-01, -1.4782e-01,  1.8931e-01, -4.9179e-01],\n",
      "        [-7.6220e-02,  1.3067e-01, -4.5782e-01,  1.4095e-01, -2.3686e-01],\n",
      "        [ 5.0237e-01,  2.8087e-02,  5.0331e-01, -5.3200e-01,  3.8055e-01],\n",
      "        [ 1.0652e-01, -2.3132e-01, -6.4909e-02,  3.4987e-01, -2.9642e-01],\n",
      "        [-3.3931e-02, -2.1990e-01, -2.8792e-01,  4.0659e-03, -4.7416e-01],\n",
      "        [ 2.3624e-01, -5.1043e-01, -3.8709e-01,  1.9342e-01, -4.2133e-01],\n",
      "        [-5.6624e-05,  1.9707e-01, -4.2585e-01, -2.3111e-01,  4.8518e-01],\n",
      "        [-1.8144e-01, -2.1147e-01,  7.0076e-02,  3.7539e-01,  3.1006e-01],\n",
      "        [ 6.3722e-02, -5.3412e-01,  3.6617e-01,  5.2300e-02,  1.8921e-01],\n",
      "        [-7.4416e-02,  1.6725e-01,  1.5728e-01,  2.4863e-01,  3.3351e-01],\n",
      "        [-2.3463e-01, -8.4814e-02,  2.9511e-01,  4.7160e-01, -7.9829e-02],\n",
      "        [-2.9469e-01,  4.0909e-01,  3.8076e-01, -3.8146e-01, -2.6894e-02],\n",
      "        [ 4.5200e-01,  5.0269e-01,  5.2263e-01,  4.7395e-01, -1.0938e-01],\n",
      "        [ 4.2323e-01,  2.2721e-01, -5.3340e-01,  3.4843e-01, -4.4454e-01]],\n",
      "       requires_grad=True)), ('encoder.layers.7.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.7.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.5439, -0.1994,  0.1488, -0.7457, -0.4723],\n",
      "        [ 0.0404,  0.7080,  0.2351, -0.3770, -0.1454],\n",
      "        [ 0.4586, -0.6510, -0.4568,  0.7500,  0.7066],\n",
      "        [-0.1919, -0.7449,  0.1390,  0.4682,  0.4774],\n",
      "        [ 0.3237, -0.6180, -0.1956, -0.3263,  0.0956]], requires_grad=True)), ('encoder.layers.7.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.7.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0480,  0.0365,  0.0014, -0.0120, -0.0038],\n",
      "        [-0.0242,  0.0482,  0.0017,  0.0425,  0.0143],\n",
      "        [-0.0074,  0.0414, -0.0512, -0.0531, -0.0077],\n",
      "        ...,\n",
      "        [-0.0330,  0.0531, -0.0230, -0.0112, -0.0463],\n",
      "        [ 0.0469, -0.0515, -0.0110,  0.0231, -0.0509],\n",
      "        [ 0.0420,  0.0057,  0.0101, -0.0424,  0.0423]], requires_grad=True)), ('encoder.layers.7.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.7.linear2.weight', Parameter containing:\n",
      "tensor([[-0.0255, -0.0063,  0.0385,  ..., -0.0034, -0.0027, -0.0263],\n",
      "        [-0.0510, -0.0106, -0.0395,  ...,  0.0008,  0.0200,  0.0499],\n",
      "        [ 0.0457,  0.0311,  0.0299,  ..., -0.0254,  0.0097,  0.0045],\n",
      "        [ 0.0442,  0.0209, -0.0332,  ...,  0.0139, -0.0096,  0.0437],\n",
      "        [-0.0420, -0.0346,  0.0018,  ..., -0.0095, -0.0335, -0.0361]],\n",
      "       requires_grad=True)), ('encoder.layers.7.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.7.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.7.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.7.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.7.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.8.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.3965, -0.3668,  0.5367, -0.5012, -0.2707],\n",
      "        [ 0.1222, -0.1496,  0.4254,  0.2358,  0.2934],\n",
      "        [-0.4749, -0.1229, -0.2082, -0.3594, -0.4542],\n",
      "        [-0.3390, -0.0868, -0.1906, -0.2718, -0.3752],\n",
      "        [ 0.0325,  0.1887, -0.4720,  0.3404,  0.4042],\n",
      "        [-0.3106,  0.5291,  0.4264, -0.0131,  0.4142],\n",
      "        [ 0.4940,  0.1950, -0.4884,  0.4083,  0.2845],\n",
      "        [ 0.3903,  0.1461, -0.3055, -0.0201, -0.1394],\n",
      "        [ 0.4862, -0.4836, -0.2321,  0.1291, -0.0097],\n",
      "        [ 0.1201, -0.4656, -0.3495, -0.5382, -0.1342],\n",
      "        [ 0.0100, -0.4444, -0.4833, -0.2385,  0.1873],\n",
      "        [-0.4414, -0.5321,  0.5438, -0.1824,  0.3372],\n",
      "        [-0.3510, -0.2558,  0.3595,  0.4669, -0.4181],\n",
      "        [ 0.2554, -0.0705,  0.1544, -0.1824, -0.0630],\n",
      "        [-0.3481,  0.0645,  0.3096,  0.2766, -0.2901]], requires_grad=True)), ('encoder.layers.8.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.8.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.7006,  0.6327, -0.5542, -0.3506,  0.2349],\n",
      "        [ 0.2695, -0.0580, -0.4926,  0.0880, -0.2686],\n",
      "        [-0.4242, -0.1438,  0.3334,  0.3768,  0.6127],\n",
      "        [-0.2432,  0.4033, -0.4244,  0.5297, -0.4207],\n",
      "        [ 0.1718,  0.5360,  0.6871,  0.7515, -0.1274]], requires_grad=True)), ('encoder.layers.8.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.8.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0117, -0.0029, -0.0342, -0.0373,  0.0388],\n",
      "        [-0.0241, -0.0519, -0.0006, -0.0225, -0.0049],\n",
      "        [-0.0386, -0.0238,  0.0130,  0.0296, -0.0276],\n",
      "        ...,\n",
      "        [-0.0179,  0.0443,  0.0213,  0.0510,  0.0298],\n",
      "        [-0.0001,  0.0502, -0.0359, -0.0516, -0.0436],\n",
      "        [ 0.0165, -0.0004,  0.0371, -0.0430,  0.0409]], requires_grad=True)), ('encoder.layers.8.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.8.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0120,  0.0380,  0.0405,  ...,  0.0480, -0.0512, -0.0346],\n",
      "        [-0.0479,  0.0315,  0.0017,  ...,  0.0032,  0.0140, -0.0161],\n",
      "        [-0.0456, -0.0509, -0.0354,  ...,  0.0497, -0.0090, -0.0386],\n",
      "        [-0.0328,  0.0527,  0.0388,  ..., -0.0057,  0.0230, -0.0147],\n",
      "        [-0.0517, -0.0077, -0.0106,  ...,  0.0170,  0.0289, -0.0182]],\n",
      "       requires_grad=True)), ('encoder.layers.8.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.8.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.8.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.8.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.8.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.9.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-4.6045e-01,  3.6514e-01, -2.8918e-02, -3.7657e-01, -1.3446e-01],\n",
      "        [-2.1916e-01,  1.2785e-01, -3.8423e-02,  3.9546e-01,  2.7325e-01],\n",
      "        [-1.2029e-01,  3.9828e-01,  4.8248e-01, -2.3863e-01, -2.0022e-01],\n",
      "        [-1.8470e-01, -4.8907e-01, -3.2508e-01, -4.5687e-01, -4.9623e-01],\n",
      "        [-5.1530e-01,  3.2675e-01,  3.3262e-01, -1.6839e-01,  3.5310e-02],\n",
      "        [-1.2487e-02, -4.9003e-01, -1.9331e-01, -5.8118e-02,  1.3160e-01],\n",
      "        [-1.1067e-01, -8.0482e-02, -4.7903e-01, -4.5797e-01, -4.0303e-01],\n",
      "        [ 8.6213e-02, -1.3067e-01,  4.0589e-01,  1.9078e-01, -1.2932e-01],\n",
      "        [ 2.4692e-01, -5.2113e-01,  4.4311e-01,  2.0763e-01, -2.0270e-02],\n",
      "        [-5.4419e-01, -3.8847e-02, -1.8588e-01,  5.1845e-01, -5.4007e-01],\n",
      "        [ 6.7532e-05, -3.9229e-01, -7.2470e-02, -1.4731e-01,  2.8381e-01],\n",
      "        [ 5.0795e-01,  4.0736e-01,  5.0541e-01,  5.1568e-01,  4.0852e-01],\n",
      "        [ 4.4487e-01, -1.8616e-01, -2.0040e-01, -5.2269e-01,  2.1990e-01],\n",
      "        [ 3.9353e-01, -5.3687e-01,  4.6322e-01,  2.9849e-02, -3.0965e-01],\n",
      "        [ 2.6733e-01, -2.3432e-01, -4.8240e-01, -4.1093e-02,  4.0037e-01]],\n",
      "       requires_grad=True)), ('encoder.layers.9.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.9.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.6107, -0.3705, -0.0734, -0.3850,  0.5379],\n",
      "        [-0.5689,  0.5254,  0.5413,  0.7108, -0.5144],\n",
      "        [-0.2077, -0.3308,  0.0963,  0.6002,  0.6253],\n",
      "        [-0.5346,  0.6692,  0.0230,  0.1995, -0.1176],\n",
      "        [ 0.3711, -0.0531,  0.1433, -0.3727,  0.1712]], requires_grad=True)), ('encoder.layers.9.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.9.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0398,  0.0262,  0.0538,  0.0010, -0.0140],\n",
      "        [ 0.0517,  0.0304, -0.0494,  0.0514,  0.0426],\n",
      "        [-0.0299, -0.0474, -0.0483,  0.0416, -0.0345],\n",
      "        ...,\n",
      "        [-0.0096,  0.0434, -0.0246, -0.0392,  0.0458],\n",
      "        [-0.0010,  0.0481, -0.0408, -0.0523, -0.0480],\n",
      "        [ 0.0393, -0.0270, -0.0485,  0.0030, -0.0058]], requires_grad=True)), ('encoder.layers.9.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.9.linear2.weight', Parameter containing:\n",
      "tensor([[ 1.2545e-02,  2.4848e-02,  2.0472e-02,  ..., -3.9197e-02,\n",
      "          6.3125e-05, -5.7615e-03],\n",
      "        [ 2.9922e-02, -3.1394e-02,  2.6666e-03,  ..., -1.2088e-02,\n",
      "          4.8996e-02, -3.2204e-02],\n",
      "        [ 1.9314e-02,  8.1391e-03, -1.5527e-02,  ..., -1.8000e-02,\n",
      "         -5.2578e-02, -4.6058e-02],\n",
      "        [-3.8225e-02, -5.2578e-02,  8.1109e-03,  ..., -2.8317e-02,\n",
      "          9.5764e-03, -3.8976e-02],\n",
      "        [ 1.5083e-02, -5.1676e-02,  4.4220e-02,  ...,  3.4192e-02,\n",
      "         -4.7299e-02, -7.8878e-03]], requires_grad=True)), ('encoder.layers.9.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.9.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.9.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.9.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.9.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.10.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.2986, -0.2889,  0.1976,  0.5018,  0.1763],\n",
      "        [ 0.4942, -0.4819, -0.1200,  0.4462,  0.2245],\n",
      "        [ 0.5428,  0.4726, -0.0061,  0.4034,  0.1789],\n",
      "        [ 0.3645, -0.4885, -0.4984,  0.4597,  0.4178],\n",
      "        [-0.3452, -0.0344,  0.4692,  0.3307,  0.0221],\n",
      "        [ 0.0571,  0.4140, -0.1922,  0.4018,  0.1540],\n",
      "        [ 0.2848,  0.5142, -0.5011, -0.1318,  0.4862],\n",
      "        [ 0.5328, -0.4590,  0.4023, -0.1242, -0.0495],\n",
      "        [ 0.4815, -0.2888, -0.3507,  0.1508, -0.3767],\n",
      "        [-0.3551,  0.5120,  0.5172,  0.1561, -0.4312],\n",
      "        [ 0.3438,  0.4229, -0.0283, -0.5086, -0.2083],\n",
      "        [ 0.1374,  0.4000,  0.0632, -0.4086, -0.0041],\n",
      "        [ 0.0972,  0.3906,  0.1933, -0.1812, -0.0415],\n",
      "        [ 0.1932, -0.1639,  0.2825, -0.1650, -0.4737],\n",
      "        [ 0.5216,  0.5355, -0.1976,  0.1759,  0.3667]], requires_grad=True)), ('encoder.layers.10.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.10.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.0689, -0.7260, -0.5663,  0.4838,  0.4919],\n",
      "        [ 0.1730, -0.3595,  0.7174,  0.0139, -0.6798],\n",
      "        [ 0.2705,  0.7742,  0.1017, -0.5359,  0.0461],\n",
      "        [-0.0264, -0.2013, -0.5946, -0.6824,  0.6217],\n",
      "        [-0.7044, -0.6123, -0.5935,  0.3831, -0.2117]], requires_grad=True)), ('encoder.layers.10.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.10.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0139,  0.0487,  0.0073, -0.0213,  0.0066],\n",
      "        [-0.0478, -0.0094, -0.0246,  0.0290,  0.0162],\n",
      "        [-0.0129,  0.0004, -0.0235, -0.0075, -0.0491],\n",
      "        ...,\n",
      "        [-0.0527,  0.0418,  0.0534, -0.0299,  0.0217],\n",
      "        [-0.0394, -0.0446, -0.0044, -0.0386,  0.0450],\n",
      "        [-0.0042,  0.0494,  0.0191,  0.0197, -0.0232]], requires_grad=True)), ('encoder.layers.10.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.10.linear2.weight', Parameter containing:\n",
      "tensor([[-0.0291,  0.0066, -0.0445,  ...,  0.0216, -0.0362,  0.0269],\n",
      "        [-0.0154, -0.0080, -0.0423,  ..., -0.0172,  0.0102, -0.0105],\n",
      "        [ 0.0077, -0.0241, -0.0347,  ..., -0.0239, -0.0486, -0.0056],\n",
      "        [ 0.0429,  0.0279, -0.0313,  ...,  0.0479,  0.0336, -0.0409],\n",
      "        [ 0.0328,  0.0339,  0.0196,  ..., -0.0261,  0.0229,  0.0496]],\n",
      "       requires_grad=True)), ('encoder.layers.10.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.10.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.10.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.10.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.10.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.11.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.5339,  0.2115,  0.4932,  0.3377,  0.4694],\n",
      "        [-0.4353, -0.4285, -0.0747, -0.1202, -0.2930],\n",
      "        [ 0.5108,  0.0243, -0.1739, -0.3984,  0.0823],\n",
      "        [ 0.4348, -0.3705,  0.1184, -0.3613, -0.4501],\n",
      "        [-0.1183, -0.2347,  0.1879, -0.0532,  0.4187],\n",
      "        [-0.0042, -0.3971,  0.0298, -0.0301,  0.2126],\n",
      "        [ 0.4843,  0.5380,  0.3282, -0.4688,  0.1191],\n",
      "        [-0.1110, -0.5301, -0.5246, -0.1008, -0.2350],\n",
      "        [ 0.5144, -0.0509,  0.1025, -0.3427, -0.1212],\n",
      "        [ 0.0931, -0.4049,  0.4441, -0.3834, -0.3494],\n",
      "        [ 0.2071,  0.0391,  0.5126, -0.0191, -0.3396],\n",
      "        [ 0.2070, -0.2176, -0.0539, -0.3256,  0.4505],\n",
      "        [ 0.1739,  0.1822,  0.2403,  0.2822,  0.3776],\n",
      "        [-0.5052, -0.1313,  0.1157,  0.1400,  0.0779],\n",
      "        [ 0.3687,  0.4324,  0.0585, -0.2700, -0.4660]], requires_grad=True)), ('encoder.layers.11.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('encoder.layers.11.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.0615,  0.0269,  0.4518,  0.5881, -0.6360],\n",
      "        [-0.4819,  0.6003,  0.7171, -0.0665, -0.4269],\n",
      "        [ 0.1898,  0.3271,  0.5637, -0.6041,  0.3962],\n",
      "        [ 0.1196,  0.2841,  0.6673, -0.1955, -0.4171],\n",
      "        [ 0.3728, -0.7048, -0.6511, -0.5493, -0.6779]], requires_grad=True)), ('encoder.layers.11.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.11.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0268, -0.0163,  0.0346,  0.0341, -0.0207],\n",
      "        [ 0.0168,  0.0415, -0.0147,  0.0199, -0.0158],\n",
      "        [-0.0245, -0.0352,  0.0252,  0.0016,  0.0422],\n",
      "        ...,\n",
      "        [ 0.0041, -0.0125,  0.0269,  0.0536, -0.0521],\n",
      "        [ 0.0377, -0.0537, -0.0408,  0.0434,  0.0151],\n",
      "        [ 0.0223,  0.0022, -0.0446,  0.0503, -0.0373]], requires_grad=True)), ('encoder.layers.11.linear1.bias', Parameter containing:\n",
      "tensor([ 0.3000,  0.1649, -0.1554,  ...,  0.3342, -0.1853, -0.2299],\n",
      "       requires_grad=True)), ('encoder.layers.11.linear2.weight', Parameter containing:\n",
      "tensor([[-0.0066, -0.0281,  0.0495,  ..., -0.0347,  0.0489,  0.0107],\n",
      "        [ 0.0225, -0.0420, -0.0262,  ..., -0.0103, -0.0536,  0.0152],\n",
      "        [-0.0202,  0.0270, -0.0441,  ..., -0.0419,  0.0210, -0.0467],\n",
      "        [-0.0337,  0.0334,  0.0261,  ..., -0.0447,  0.0074, -0.0304],\n",
      "        [ 0.0455,  0.0466,  0.0443,  ...,  0.0442,  0.0017, -0.0263]],\n",
      "       requires_grad=True)), ('encoder.layers.11.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0217, -0.0156, -0.0042, -0.0124, -0.0159], requires_grad=True)), ('encoder.layers.11.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.11.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.layers.11.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.layers.11.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('encoder.norm.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('encoder.norm.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.0.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.4285, -0.4286, -0.3463,  0.0350, -0.2462],\n",
      "        [ 0.2326, -0.3562,  0.3227,  0.5404, -0.1409],\n",
      "        [-0.0154, -0.5242, -0.4034,  0.5385,  0.2063],\n",
      "        [-0.1413,  0.3124, -0.0039, -0.3915, -0.0950],\n",
      "        [ 0.5327, -0.0135,  0.0421,  0.4366, -0.2667],\n",
      "        [ 0.2656, -0.4589,  0.4198,  0.1205, -0.2746],\n",
      "        [ 0.3381, -0.0011,  0.3492, -0.3669, -0.3433],\n",
      "        [-0.1566,  0.2115,  0.2956,  0.4316,  0.0015],\n",
      "        [-0.5441,  0.4204,  0.4410,  0.1178, -0.2680],\n",
      "        [-0.1994, -0.3758, -0.0145,  0.3425,  0.4446],\n",
      "        [-0.2277,  0.3795, -0.1083,  0.2524,  0.3408],\n",
      "        [ 0.3185,  0.4007,  0.0649,  0.4710,  0.3267],\n",
      "        [ 0.1673,  0.1317, -0.4527, -0.1295,  0.0562],\n",
      "        [ 0.5018, -0.1643,  0.2845, -0.2498, -0.1148],\n",
      "        [ 0.4634,  0.0446, -0.3325, -0.5355,  0.2762]], requires_grad=True)), ('decoder.layers.0.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.0.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.2982,  0.7005, -0.3750, -0.5881,  0.0988],\n",
      "        [-0.2544, -0.1022,  0.1448,  0.6490, -0.5137],\n",
      "        [-0.6492,  0.7189, -0.5156,  0.4578, -0.5490],\n",
      "        [-0.0632, -0.2320,  0.3632,  0.6397, -0.7080],\n",
      "        [-0.1925,  0.4600, -0.3954,  0.5744, -0.2694]], requires_grad=True)), ('decoder.layers.0.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.0.multihead_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.5391,  0.4281, -0.4274, -0.0580, -0.4447],\n",
      "        [-0.1672, -0.4292,  0.4120, -0.1593,  0.1644],\n",
      "        [-0.5450, -0.0614, -0.2378,  0.3434, -0.5342],\n",
      "        [-0.3828,  0.3479, -0.2229, -0.2856, -0.4900],\n",
      "        [ 0.4839, -0.1368, -0.2687,  0.0754, -0.3377],\n",
      "        [-0.2680, -0.3683, -0.3692,  0.3734,  0.1216],\n",
      "        [ 0.5071,  0.1834, -0.1259, -0.4496, -0.2872],\n",
      "        [ 0.1996,  0.5060,  0.1108,  0.4722,  0.1471],\n",
      "        [-0.4669, -0.1289, -0.3037, -0.0563,  0.0617],\n",
      "        [-0.1757, -0.2999, -0.3821, -0.5378,  0.3119],\n",
      "        [-0.4001, -0.0955, -0.2964,  0.5397, -0.2354],\n",
      "        [-0.2609, -0.3535, -0.2858,  0.0541, -0.4176],\n",
      "        [ 0.4644, -0.0056, -0.2465,  0.1786,  0.2591],\n",
      "        [-0.3275,  0.2690,  0.3888, -0.0040, -0.0512],\n",
      "        [-0.3343,  0.4513,  0.3560,  0.1786, -0.3394]], requires_grad=True)), ('decoder.layers.0.multihead_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.0.multihead_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.1464, -0.5236, -0.1782,  0.3036,  0.3906],\n",
      "        [-0.7710, -0.3199,  0.5312, -0.7476, -0.2931],\n",
      "        [ 0.2524,  0.6713, -0.6629,  0.0098,  0.4881],\n",
      "        [ 0.4657,  0.0687,  0.6923,  0.4769, -0.4763],\n",
      "        [-0.1508, -0.6628,  0.5632, -0.6154, -0.5423]], requires_grad=True)), ('decoder.layers.0.multihead_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.0.linear1.weight', Parameter containing:\n",
      "tensor([[-9.5564e-03,  3.5364e-02,  2.2305e-02,  2.9606e-02,  4.9565e-02],\n",
      "        [-3.1696e-02,  4.9826e-04,  5.3981e-03, -4.4715e-02, -2.6014e-03],\n",
      "        [ 1.2628e-02,  6.9332e-03,  3.0677e-02,  2.3798e-02, -3.6699e-02],\n",
      "        ...,\n",
      "        [ 2.4974e-03, -3.9019e-02,  3.7043e-02,  5.0724e-02, -7.7754e-03],\n",
      "        [-3.4020e-02, -2.7580e-03,  3.8505e-02,  5.1185e-02,  5.0343e-02],\n",
      "        [-4.2889e-05,  3.9627e-02, -1.6445e-02,  8.6212e-03, -3.8009e-02]],\n",
      "       requires_grad=True)), ('decoder.layers.0.linear1.bias', Parameter containing:\n",
      "tensor([ 0.4438,  0.2509, -0.0317,  ..., -0.1585,  0.2640,  0.1478],\n",
      "       requires_grad=True)), ('decoder.layers.0.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0197, -0.0048, -0.0102,  ...,  0.0388, -0.0337, -0.0378],\n",
      "        [ 0.0440,  0.0171, -0.0328,  ..., -0.0249, -0.0300, -0.0499],\n",
      "        [-0.0318,  0.0451,  0.0171,  ..., -0.0460, -0.0492, -0.0210],\n",
      "        [ 0.0371, -0.0159, -0.0374,  ...,  0.0365,  0.0135,  0.0356],\n",
      "        [-0.0509,  0.0306,  0.0041,  ...,  0.0341, -0.0074, -0.0529]],\n",
      "       requires_grad=True)), ('decoder.layers.0.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0183, -0.0083,  0.0108,  0.0040, -0.0033], requires_grad=True)), ('decoder.layers.0.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.0.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.0.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.0.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.0.norm3.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.0.norm3.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.1.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.4453, -0.0371,  0.3436, -0.1594, -0.3540],\n",
      "        [-0.2620,  0.2936, -0.2416, -0.1926, -0.2242],\n",
      "        [-0.3897,  0.4699,  0.0689, -0.1525,  0.0229],\n",
      "        [ 0.0452, -0.3337, -0.2425,  0.4919,  0.1329],\n",
      "        [-0.3511, -0.4591, -0.1717, -0.3388, -0.3785],\n",
      "        [-0.2690, -0.3227,  0.0965,  0.3680, -0.1749],\n",
      "        [ 0.2928, -0.1212, -0.0051, -0.2936, -0.3243],\n",
      "        [-0.2138,  0.0976,  0.3952,  0.2824, -0.3430],\n",
      "        [ 0.3029,  0.2163,  0.3910, -0.3407,  0.1512],\n",
      "        [ 0.2788, -0.3555,  0.3495, -0.1452, -0.2955],\n",
      "        [ 0.1961,  0.4720, -0.1100,  0.3920, -0.3401],\n",
      "        [-0.2792,  0.2737, -0.3748, -0.4668,  0.4239],\n",
      "        [ 0.0697, -0.0419,  0.2323, -0.1923,  0.2402],\n",
      "        [-0.5178,  0.3994,  0.2656,  0.1919, -0.2292],\n",
      "        [ 0.4548, -0.3847,  0.0195,  0.2438,  0.3439]], requires_grad=True)), ('decoder.layers.1.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.1.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.4008, -0.4491, -0.2981, -0.3553,  0.7734],\n",
      "        [-0.4754,  0.6924, -0.3946, -0.5191, -0.4580],\n",
      "        [-0.5357,  0.2829,  0.6088, -0.7094, -0.6154],\n",
      "        [ 0.4902,  0.2742, -0.4964,  0.5060, -0.0432],\n",
      "        [-0.2535,  0.6188, -0.6343, -0.2208,  0.1664]], requires_grad=True)), ('decoder.layers.1.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.1.multihead_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.4889,  0.0909,  0.2326, -0.3756,  0.1165],\n",
      "        [-0.3299,  0.2934, -0.4598,  0.3475, -0.1581],\n",
      "        [-0.0566,  0.4617, -0.2987,  0.1475, -0.0212],\n",
      "        [ 0.3693, -0.0355,  0.1835,  0.0490, -0.3202],\n",
      "        [-0.2505, -0.2479,  0.2839, -0.0547, -0.0710],\n",
      "        [ 0.2857,  0.3247, -0.2965,  0.2482, -0.4127],\n",
      "        [ 0.2484,  0.0577,  0.3617,  0.0055, -0.3670],\n",
      "        [-0.0006,  0.1852,  0.1935, -0.3109, -0.3909],\n",
      "        [-0.2320, -0.4306,  0.0481, -0.4815, -0.1780],\n",
      "        [-0.1215, -0.3339,  0.0646,  0.5410, -0.3219],\n",
      "        [-0.0297, -0.2362, -0.0464,  0.5184, -0.1902],\n",
      "        [-0.0340,  0.3664, -0.2333,  0.2752, -0.4911],\n",
      "        [ 0.0116,  0.0206,  0.4038, -0.0884,  0.2071],\n",
      "        [-0.1091, -0.5287,  0.2164,  0.0946,  0.4240],\n",
      "        [ 0.4934,  0.2316,  0.2847, -0.5080, -0.2376]], requires_grad=True)), ('decoder.layers.1.multihead_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.1.multihead_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.5326,  0.5214,  0.1618,  0.2057,  0.1611],\n",
      "        [-0.3393,  0.0565,  0.3937, -0.0844, -0.6145],\n",
      "        [-0.6359, -0.6855, -0.7546, -0.1785, -0.7248],\n",
      "        [-0.5179, -0.3700,  0.6213,  0.2573,  0.2296],\n",
      "        [ 0.2921,  0.2720,  0.5237, -0.7595,  0.0970]], requires_grad=True)), ('decoder.layers.1.multihead_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.1.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0435,  0.0137,  0.0342, -0.0381, -0.0318],\n",
      "        [ 0.0279,  0.0472,  0.0153,  0.0141,  0.0400],\n",
      "        [ 0.0384, -0.0323,  0.0449, -0.0284,  0.0360],\n",
      "        ...,\n",
      "        [ 0.0526,  0.0403, -0.0161, -0.0356, -0.0060],\n",
      "        [-0.0135, -0.0028,  0.0361, -0.0470,  0.0349],\n",
      "        [-0.0063,  0.0154,  0.0525,  0.0191,  0.0085]], requires_grad=True)), ('decoder.layers.1.linear1.bias', Parameter containing:\n",
      "tensor([ 0.4438,  0.2509, -0.0317,  ..., -0.1585,  0.2640,  0.1478],\n",
      "       requires_grad=True)), ('decoder.layers.1.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0157, -0.0036, -0.0204,  ..., -0.0285, -0.0249,  0.0199],\n",
      "        [-0.0077,  0.0411, -0.0501,  ..., -0.0280, -0.0313, -0.0112],\n",
      "        [-0.0130, -0.0251,  0.0353,  ...,  0.0307,  0.0029, -0.0004],\n",
      "        [ 0.0191, -0.0396, -0.0053,  ...,  0.0317, -0.0307, -0.0512],\n",
      "        [-0.0136, -0.0475, -0.0454,  ..., -0.0257,  0.0230, -0.0256]],\n",
      "       requires_grad=True)), ('decoder.layers.1.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0183, -0.0083,  0.0108,  0.0040, -0.0033], requires_grad=True)), ('decoder.layers.1.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.1.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.1.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.1.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.1.norm3.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.1.norm3.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.2.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.2855,  0.2359, -0.3926,  0.2679,  0.0499],\n",
      "        [-0.3044,  0.2596, -0.1934,  0.0823, -0.4550],\n",
      "        [ 0.1672, -0.2215, -0.2792, -0.0889, -0.2567],\n",
      "        [ 0.2241, -0.4203, -0.2452, -0.1613,  0.2089],\n",
      "        [ 0.4676, -0.0794, -0.0799, -0.3624, -0.2768],\n",
      "        [ 0.2350,  0.3379,  0.0606, -0.0030,  0.0343],\n",
      "        [ 0.0314,  0.2210,  0.1596, -0.5415, -0.5062],\n",
      "        [-0.3764,  0.1671, -0.3869, -0.4798,  0.0095],\n",
      "        [-0.1373,  0.4850, -0.1324,  0.4866,  0.0303],\n",
      "        [-0.2862,  0.0660, -0.4361, -0.0932, -0.0391],\n",
      "        [ 0.1566, -0.1536,  0.5312,  0.3812, -0.0903],\n",
      "        [ 0.3717, -0.0275,  0.4311, -0.4802,  0.1129],\n",
      "        [-0.1640,  0.2308, -0.3405, -0.0794,  0.0168],\n",
      "        [ 0.1561, -0.5439, -0.1998, -0.3350, -0.5398],\n",
      "        [-0.5353,  0.0979, -0.5277, -0.4578, -0.0274]], requires_grad=True)), ('decoder.layers.2.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.2.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.6661, -0.2301, -0.4181, -0.3968,  0.0378],\n",
      "        [ 0.5933, -0.0461,  0.1072,  0.4613,  0.2635],\n",
      "        [-0.3541, -0.0263, -0.4016,  0.2628, -0.3937],\n",
      "        [-0.3551, -0.3128, -0.6894, -0.3873,  0.1821],\n",
      "        [ 0.5363,  0.6293,  0.7715, -0.2798, -0.4927]], requires_grad=True)), ('decoder.layers.2.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.2.multihead_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.1438, -0.4393, -0.4050,  0.2207, -0.0544],\n",
      "        [-0.3073, -0.4159, -0.2179, -0.5275, -0.4696],\n",
      "        [-0.0580,  0.3276,  0.5345,  0.2373,  0.5046],\n",
      "        [ 0.1906,  0.4115,  0.4803, -0.0795,  0.4377],\n",
      "        [-0.0404, -0.2158, -0.0471,  0.0179, -0.3550],\n",
      "        [ 0.4091,  0.3822,  0.2951, -0.4075, -0.5311],\n",
      "        [ 0.1370,  0.4425,  0.4222,  0.0427, -0.2045],\n",
      "        [-0.2956, -0.1072,  0.1447, -0.4987,  0.1972],\n",
      "        [-0.0832, -0.4910,  0.2617, -0.3812, -0.0730],\n",
      "        [-0.1992,  0.3260,  0.0552, -0.1949,  0.4638],\n",
      "        [-0.0984,  0.2215, -0.1286,  0.5434, -0.0571],\n",
      "        [ 0.4663,  0.5196,  0.1821, -0.3709,  0.3946],\n",
      "        [-0.2829, -0.1922,  0.3212, -0.3638, -0.1704],\n",
      "        [ 0.2679,  0.1700,  0.1169, -0.5187, -0.4344],\n",
      "        [-0.2820, -0.1570,  0.0843, -0.3713, -0.2627]], requires_grad=True)), ('decoder.layers.2.multihead_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.2.multihead_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.0472,  0.0990,  0.4077, -0.5894, -0.3893],\n",
      "        [ 0.7423,  0.2815,  0.3224, -0.2018, -0.4674],\n",
      "        [-0.6950, -0.4523, -0.2708,  0.0792,  0.6698],\n",
      "        [ 0.1362,  0.3657, -0.5169, -0.3569, -0.1643],\n",
      "        [-0.1032, -0.3635,  0.3509, -0.3360,  0.5396]], requires_grad=True)), ('decoder.layers.2.multihead_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.2.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0322,  0.0165,  0.0260,  0.0512,  0.0139],\n",
      "        [ 0.0487,  0.0304, -0.0280, -0.0172,  0.0337],\n",
      "        [ 0.0521,  0.0103,  0.0003,  0.0408,  0.0045],\n",
      "        ...,\n",
      "        [ 0.0267, -0.0451,  0.0533, -0.0237,  0.0030],\n",
      "        [-0.0083, -0.0008,  0.0171,  0.0322,  0.0414],\n",
      "        [-0.0292,  0.0217, -0.0390, -0.0312,  0.0423]], requires_grad=True)), ('decoder.layers.2.linear1.bias', Parameter containing:\n",
      "tensor([ 0.4438,  0.2509, -0.0317,  ..., -0.1585,  0.2640,  0.1478],\n",
      "       requires_grad=True)), ('decoder.layers.2.linear2.weight', Parameter containing:\n",
      "tensor([[-0.0239,  0.0497,  0.0147,  ..., -0.0526,  0.0174,  0.0294],\n",
      "        [ 0.0374,  0.0029, -0.0509,  ..., -0.0463,  0.0512,  0.0449],\n",
      "        [ 0.0142,  0.0129,  0.0462,  ...,  0.0317, -0.0084, -0.0472],\n",
      "        [ 0.0425, -0.0112, -0.0253,  ...,  0.0088,  0.0384,  0.0060],\n",
      "        [-0.0218, -0.0150, -0.0153,  ...,  0.0391,  0.0529, -0.0427]],\n",
      "       requires_grad=True)), ('decoder.layers.2.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0183, -0.0083,  0.0108,  0.0040, -0.0033], requires_grad=True)), ('decoder.layers.2.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.2.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.2.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.2.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.2.norm3.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.2.norm3.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.3.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.1664,  0.4596,  0.1530, -0.0456, -0.2290],\n",
      "        [ 0.2311,  0.0714, -0.0603,  0.1815, -0.4724],\n",
      "        [-0.3560,  0.2635, -0.2627,  0.1285,  0.4835],\n",
      "        [-0.5195, -0.3276,  0.1812, -0.0125, -0.4264],\n",
      "        [-0.1928,  0.1721,  0.0550, -0.0424,  0.0716],\n",
      "        [ 0.0540, -0.1575, -0.2906,  0.4224,  0.0678],\n",
      "        [-0.2314,  0.5040,  0.0832, -0.4158,  0.3667],\n",
      "        [-0.1237,  0.3654, -0.2872,  0.4371,  0.4793],\n",
      "        [-0.2143,  0.2078,  0.2148, -0.3796, -0.1592],\n",
      "        [-0.1473,  0.4165, -0.1669, -0.2064,  0.0598],\n",
      "        [-0.4198,  0.2437, -0.2332,  0.0098,  0.3967],\n",
      "        [ 0.5192,  0.0661, -0.4345, -0.4637, -0.2169],\n",
      "        [ 0.5121,  0.0905,  0.2870, -0.0788, -0.3490],\n",
      "        [ 0.4590,  0.0625,  0.3459, -0.1852, -0.4259],\n",
      "        [ 0.2000,  0.2970, -0.3496, -0.3304,  0.2973]], requires_grad=True)), ('decoder.layers.3.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.3.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.0501,  0.5831,  0.5274, -0.4528,  0.5433],\n",
      "        [-0.7054, -0.1606, -0.4308, -0.7437, -0.7248],\n",
      "        [-0.2991, -0.7136,  0.0783, -0.2536,  0.2393],\n",
      "        [ 0.7132,  0.7564, -0.2717,  0.0495,  0.6723],\n",
      "        [-0.2897,  0.5003, -0.5236, -0.5048, -0.2191]], requires_grad=True)), ('decoder.layers.3.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.3.multihead_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.0507,  0.3391,  0.0299,  0.1677, -0.0512],\n",
      "        [-0.0258, -0.0374,  0.3484,  0.0629, -0.3525],\n",
      "        [ 0.5114,  0.4916, -0.2958,  0.4066, -0.3165],\n",
      "        [ 0.0256,  0.3782,  0.2423, -0.3131, -0.3039],\n",
      "        [-0.3997,  0.4628,  0.1441,  0.3620, -0.4463],\n",
      "        [-0.3212,  0.2612,  0.2344,  0.1250, -0.1983],\n",
      "        [-0.4246,  0.4328, -0.4296,  0.1525,  0.3993],\n",
      "        [ 0.0124,  0.1982, -0.1100,  0.3429,  0.4405],\n",
      "        [ 0.3873,  0.1416,  0.4471, -0.4877, -0.0965],\n",
      "        [ 0.1065,  0.1779,  0.0943, -0.0479,  0.0530],\n",
      "        [-0.3922, -0.5352,  0.3130,  0.2026,  0.2630],\n",
      "        [ 0.0875,  0.4043,  0.3879, -0.5363,  0.3210],\n",
      "        [-0.3259, -0.3523, -0.2870,  0.1154,  0.1437],\n",
      "        [ 0.0848,  0.2991, -0.2658,  0.2252,  0.2403],\n",
      "        [-0.0037, -0.0738,  0.3482, -0.0815, -0.0201]], requires_grad=True)), ('decoder.layers.3.multihead_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.3.multihead_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[ 0.6399, -0.5144,  0.0765, -0.5728, -0.1878],\n",
      "        [-0.5854, -0.3570,  0.2147,  0.4890,  0.6556],\n",
      "        [-0.0804,  0.5315, -0.6203, -0.0023,  0.7062],\n",
      "        [ 0.0302, -0.7068,  0.1293,  0.2116, -0.4685],\n",
      "        [-0.3767, -0.5848,  0.1325,  0.1407,  0.4802]], requires_grad=True)), ('decoder.layers.3.multihead_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.3.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0160, -0.0220,  0.0381, -0.0096, -0.0339],\n",
      "        [ 0.0394,  0.0114,  0.0298, -0.0156, -0.0282],\n",
      "        [-0.0021, -0.0477, -0.0032,  0.0537, -0.0381],\n",
      "        ...,\n",
      "        [-0.0194,  0.0119,  0.0109, -0.0541,  0.0216],\n",
      "        [-0.0291,  0.0448, -0.0157,  0.0040, -0.0281],\n",
      "        [-0.0207, -0.0477, -0.0186,  0.0184,  0.0279]], requires_grad=True)), ('decoder.layers.3.linear1.bias', Parameter containing:\n",
      "tensor([ 0.4438,  0.2509, -0.0317,  ..., -0.1585,  0.2640,  0.1478],\n",
      "       requires_grad=True)), ('decoder.layers.3.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0102,  0.0470, -0.0466,  ...,  0.0200,  0.0351,  0.0084],\n",
      "        [ 0.0241,  0.0446, -0.0011,  ..., -0.0436, -0.0509,  0.0284],\n",
      "        [ 0.0257, -0.0300, -0.0433,  ..., -0.0447, -0.0533, -0.0385],\n",
      "        [ 0.0466,  0.0401, -0.0343,  ..., -0.0213,  0.0460, -0.0356],\n",
      "        [ 0.0204, -0.0524,  0.0230,  ...,  0.0324, -0.0183, -0.0187]],\n",
      "       requires_grad=True)), ('decoder.layers.3.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0183, -0.0083,  0.0108,  0.0040, -0.0033], requires_grad=True)), ('decoder.layers.3.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.3.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.3.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.3.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.3.norm3.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.3.norm3.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.4.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.2139, -0.1803,  0.4664,  0.5355, -0.4889],\n",
      "        [-0.2564, -0.3333, -0.4776,  0.2277,  0.4548],\n",
      "        [ 0.2898,  0.5017,  0.3467, -0.0437,  0.4499],\n",
      "        [-0.4567,  0.0252,  0.3251, -0.1613,  0.4524],\n",
      "        [-0.3054, -0.1574,  0.0965, -0.2881,  0.0844],\n",
      "        [-0.3578, -0.3384, -0.4020,  0.1713,  0.1745],\n",
      "        [-0.0988, -0.2606, -0.0087,  0.2937, -0.3119],\n",
      "        [ 0.1850, -0.2616, -0.2365, -0.1939, -0.3189],\n",
      "        [ 0.0927, -0.3952,  0.5020,  0.1286, -0.3565],\n",
      "        [-0.3594, -0.0296,  0.2088, -0.1962,  0.1144],\n",
      "        [ 0.2373,  0.3049, -0.3519, -0.3059,  0.4704],\n",
      "        [-0.3038, -0.3250,  0.2205,  0.5224,  0.5052],\n",
      "        [ 0.0691, -0.5024,  0.1966,  0.3097,  0.1748],\n",
      "        [-0.3444,  0.3120,  0.2863, -0.4972, -0.2694],\n",
      "        [ 0.0502,  0.4076, -0.4224,  0.4114,  0.4929]], requires_grad=True)), ('decoder.layers.4.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.4.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.5933,  0.6152,  0.4834, -0.0269,  0.5979],\n",
      "        [-0.5203,  0.3572,  0.2812, -0.0579, -0.2497],\n",
      "        [ 0.1923, -0.7513,  0.5077,  0.4435, -0.6738],\n",
      "        [-0.0316,  0.0150, -0.3470, -0.4824,  0.6452],\n",
      "        [ 0.1939,  0.6923,  0.4269, -0.0100,  0.0568]], requires_grad=True)), ('decoder.layers.4.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.4.multihead_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.4895, -0.0692, -0.3649,  0.0470, -0.1434],\n",
      "        [-0.5022, -0.4589,  0.2640, -0.4773,  0.3224],\n",
      "        [-0.5388,  0.2858, -0.0449,  0.1217,  0.3989],\n",
      "        [ 0.1905,  0.4338,  0.4366,  0.4589, -0.2199],\n",
      "        [ 0.1781, -0.1313,  0.3493, -0.0623,  0.3629],\n",
      "        [-0.2718,  0.3255, -0.0886,  0.1552,  0.3795],\n",
      "        [ 0.4199,  0.2878, -0.1988,  0.0956,  0.4083],\n",
      "        [ 0.4534,  0.4136,  0.2013,  0.0282, -0.2740],\n",
      "        [ 0.5070,  0.2350, -0.0881,  0.2059, -0.2698],\n",
      "        [-0.3167,  0.1198,  0.3346,  0.5420, -0.1638],\n",
      "        [ 0.0936, -0.1834,  0.3226,  0.3310, -0.0887],\n",
      "        [-0.3353,  0.2327,  0.2188,  0.3977,  0.1202],\n",
      "        [ 0.1399,  0.2172,  0.3335, -0.0265, -0.2835],\n",
      "        [-0.0633, -0.0635, -0.3634, -0.0869, -0.5279],\n",
      "        [ 0.5314,  0.4903, -0.1175, -0.3814, -0.4806]], requires_grad=True)), ('decoder.layers.4.multihead_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.4.multihead_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.3931, -0.4873,  0.7363,  0.6740,  0.6151],\n",
      "        [-0.4415, -0.1646, -0.0363, -0.6851,  0.5548],\n",
      "        [ 0.5375,  0.5533, -0.2739, -0.4587,  0.2937],\n",
      "        [-0.3886,  0.4726, -0.0077, -0.2090,  0.4963],\n",
      "        [-0.3437,  0.5062, -0.6037, -0.4162,  0.1917]], requires_grad=True)), ('decoder.layers.4.multihead_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.4.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0317, -0.0505, -0.0399,  0.0111,  0.0418],\n",
      "        [-0.0434,  0.0268,  0.0490, -0.0384,  0.0260],\n",
      "        [-0.0257, -0.0436,  0.0070, -0.0123,  0.0095],\n",
      "        ...,\n",
      "        [ 0.0091, -0.0047,  0.0430, -0.0535, -0.0102],\n",
      "        [ 0.0472, -0.0466, -0.0428, -0.0180,  0.0096],\n",
      "        [ 0.0392,  0.0097, -0.0157, -0.0214, -0.0140]], requires_grad=True)), ('decoder.layers.4.linear1.bias', Parameter containing:\n",
      "tensor([ 0.4438,  0.2509, -0.0317,  ..., -0.1585,  0.2640,  0.1478],\n",
      "       requires_grad=True)), ('decoder.layers.4.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0022, -0.0006, -0.0050,  ..., -0.0228,  0.0079,  0.0302],\n",
      "        [-0.0495, -0.0218,  0.0246,  ...,  0.0292, -0.0100,  0.0250],\n",
      "        [-0.0035,  0.0017,  0.0195,  ...,  0.0539, -0.0272,  0.0380],\n",
      "        [ 0.0295,  0.0198, -0.0211,  ...,  0.0185,  0.0484,  0.0153],\n",
      "        [ 0.0237,  0.0044,  0.0171,  ...,  0.0212,  0.0041, -0.0419]],\n",
      "       requires_grad=True)), ('decoder.layers.4.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0183, -0.0083,  0.0108,  0.0040, -0.0033], requires_grad=True)), ('decoder.layers.4.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.4.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.4.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.4.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.4.norm3.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.4.norm3.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.5.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.5073,  0.1959,  0.2613,  0.3982, -0.4719],\n",
      "        [-0.0092, -0.4003,  0.1185, -0.1182, -0.5221],\n",
      "        [-0.1756,  0.3716, -0.1449,  0.1733,  0.1179],\n",
      "        [-0.0769, -0.2017,  0.0499, -0.2262,  0.2971],\n",
      "        [ 0.0028, -0.4780, -0.5053,  0.5258,  0.1904],\n",
      "        [-0.5307, -0.0522,  0.1313,  0.4497,  0.3087],\n",
      "        [ 0.1202, -0.1900,  0.0148, -0.1242,  0.3581],\n",
      "        [-0.0562,  0.1272,  0.1257, -0.1157,  0.2996],\n",
      "        [ 0.5080,  0.0841, -0.5005, -0.0791, -0.2424],\n",
      "        [ 0.2520,  0.1641,  0.1319, -0.4188, -0.5438],\n",
      "        [-0.3417, -0.1474, -0.0795,  0.3589, -0.4266],\n",
      "        [ 0.5472,  0.2475, -0.2586, -0.2271, -0.3443],\n",
      "        [ 0.0560,  0.4962,  0.4971,  0.1342,  0.3421],\n",
      "        [-0.0229, -0.3663,  0.4436, -0.1989, -0.2336],\n",
      "        [ 0.5244,  0.2163, -0.2661, -0.4783,  0.1772]], requires_grad=True)), ('decoder.layers.5.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.5.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.1717, -0.1299,  0.4008, -0.3113,  0.5240],\n",
      "        [ 0.2366, -0.2533, -0.1853,  0.6133,  0.5076],\n",
      "        [-0.6865, -0.0611, -0.6489,  0.2115,  0.6037],\n",
      "        [-0.2570, -0.4339,  0.6297,  0.1676,  0.1772],\n",
      "        [ 0.1850,  0.4375,  0.5097, -0.1234,  0.2673]], requires_grad=True)), ('decoder.layers.5.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.5.multihead_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.4029, -0.0174,  0.5367,  0.0204,  0.0672],\n",
      "        [-0.4252, -0.3129, -0.5162,  0.4851,  0.0186],\n",
      "        [ 0.5280,  0.4991, -0.2493, -0.2994,  0.0788],\n",
      "        [ 0.1868,  0.4995, -0.1951,  0.4473,  0.2113],\n",
      "        [ 0.3202,  0.5044, -0.1717,  0.4494, -0.1241],\n",
      "        [-0.4967,  0.1117,  0.1580, -0.2140,  0.2773],\n",
      "        [-0.0198,  0.3277, -0.4735, -0.2043, -0.4534],\n",
      "        [ 0.0837, -0.2826, -0.4706, -0.3973, -0.4515],\n",
      "        [ 0.2271, -0.2648,  0.3869,  0.5217, -0.2914],\n",
      "        [-0.2279, -0.2518, -0.4499, -0.1210,  0.4093],\n",
      "        [ 0.3218, -0.3658,  0.3091, -0.3654, -0.3057],\n",
      "        [ 0.1919,  0.0793,  0.3921,  0.5309,  0.3830],\n",
      "        [ 0.0251,  0.3900,  0.2656,  0.5386,  0.3836],\n",
      "        [ 0.2857,  0.1473, -0.5260, -0.4522,  0.0160],\n",
      "        [ 0.5201,  0.3768, -0.2420, -0.2458,  0.3583]], requires_grad=True)), ('decoder.layers.5.multihead_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('decoder.layers.5.multihead_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.1196, -0.4343, -0.4640, -0.4934,  0.3019],\n",
      "        [ 0.3084, -0.4534,  0.2381,  0.2067,  0.5847],\n",
      "        [ 0.1431,  0.7329, -0.1563, -0.2805, -0.7419],\n",
      "        [-0.5656,  0.7225, -0.2906,  0.5453, -0.5374],\n",
      "        [-0.3441, -0.0308,  0.6856,  0.0020, -0.5155]], requires_grad=True)), ('decoder.layers.5.multihead_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.5.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0062,  0.0002, -0.0125, -0.0058, -0.0454],\n",
      "        [ 0.0329, -0.0306,  0.0165, -0.0353,  0.0329],\n",
      "        [ 0.0504, -0.0326,  0.0373, -0.0228,  0.0036],\n",
      "        ...,\n",
      "        [-0.0101,  0.0009, -0.0354,  0.0460, -0.0383],\n",
      "        [ 0.0390, -0.0200, -0.0339, -0.0301,  0.0029],\n",
      "        [ 0.0246, -0.0368, -0.0156,  0.0022,  0.0043]], requires_grad=True)), ('decoder.layers.5.linear1.bias', Parameter containing:\n",
      "tensor([ 0.4438,  0.2509, -0.0317,  ..., -0.1585,  0.2640,  0.1478],\n",
      "       requires_grad=True)), ('decoder.layers.5.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0429,  0.0210,  0.0495,  ...,  0.0361,  0.0440,  0.0320],\n",
      "        [ 0.0487,  0.0219,  0.0051,  ..., -0.0197, -0.0493,  0.0101],\n",
      "        [ 0.0186, -0.0527, -0.0035,  ...,  0.0087,  0.0025,  0.0132],\n",
      "        [ 0.0256,  0.0518,  0.0450,  ..., -0.0084, -0.0079,  0.0202],\n",
      "        [ 0.0018,  0.0088,  0.0225,  ..., -0.0292, -0.0243,  0.0152]],\n",
      "       requires_grad=True)), ('decoder.layers.5.linear2.bias', Parameter containing:\n",
      "tensor([ 0.0183, -0.0083,  0.0108,  0.0040, -0.0033], requires_grad=True)), ('decoder.layers.5.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.5.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.5.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.5.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.layers.5.norm3.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.layers.5.norm3.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)), ('decoder.norm.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)), ('decoder.norm.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "device='cpu'\n",
    "\n",
    "transformer_model = nn.Transformer(d_model=5,nhead=5, num_encoder_layers=12).to(device)\n",
    "src = torch.rand((2, 4, 5),device=device)  #source sequence length, batch size, feature number\n",
    "tgt = torch.rand((3, 4, 5),device=device)  #target sequence length, batch size, feature number\n",
    "out = transformer_model(src, tgt)\n",
    "\n",
    "print(\"输入x：\")\n",
    "print(src)\n",
    "print(\"输入y（标注）：\")\n",
    "print(tgt)\n",
    "print(\"输出y（预测）：\")\n",
    "print(out)\n",
    "\n",
    "out.backward(torch.ones_like(out))\n",
    "print(list(transformer_model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.9/site-packages/torch/onnx/utils.py:641: UserWarning: Constant folding - unsupported opset version. Constant folding not applied. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1655536019157/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:347.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.9/site-packages/torch/onnx/utils.py:1100: UserWarning: Constant folding - unsupported opset version. Constant folding not applied. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1655536019157/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:347.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(transformer_model,(src,tgt),'transformer.onnx',export_params=True,opset_version=8,) #BATCH调为1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a4b0b103f443abab642cb805870998419f99b3b67480212ee124b95ac521b42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
