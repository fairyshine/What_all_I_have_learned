[ã€ğŸš€æ€»ç»“ã€‘NLPæ—¥å¸¸å®è·µç»éªŒ](detail/NLP/ä¸ªäººNLPå®è·µç»éªŒ.md)



[ã€ğŸš€ç¬”è®°ã€‘CS224N](detail/NLP/CS224N-2019/CS224Nç¬”è®°.md)



# --PTMs--

Pre-training Modelsï¼ŒNLPç›¸å…³é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹

[ã€ğŸš€èµ„æ–™ã€‘-PTM-NLPæ¦‚è§ˆ](detail/NLP/PTMæ¦‚è§ˆ.md)



![NLPèŒƒå¼å˜è¿](pic/NLPèŒƒå¼å˜è¿.jpg)

1. Feature Engineeringï¼šå³ä½¿ç”¨æ–‡æœ¬ç‰¹å¾ï¼Œä¾‹å¦‚è¯æ€§ï¼Œé•¿åº¦ç­‰ï¼Œåœ¨ä½¿ç”¨æœºå™¨å­¦ä¹ çš„æ–¹æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚ï¼ˆæ— é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼‰
2. Architecture Engineeringï¼šåœ¨W2VåŸºç¡€ä¸Šï¼Œåˆ©ç”¨æ·±åº¦æ¨¡å‹ï¼ŒåŠ ä¸Šå›ºå®šçš„embeddingã€‚ï¼ˆæœ‰å›ºå®šé¢„è®­ç»ƒembeddingï¼Œä½†ä¸ä¸‹æ¸¸ä»»åŠ¡æ— ç›´æ¥å…³ç³»ï¼‰
3. Objective Engineeringï¼šåœ¨bert çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨åŠ¨æ€çš„embeddingï¼Œåœ¨åŠ ä¸Šfine-tuningã€‚ï¼ˆæœ‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä½†ä¸ä¸‹æ¸¸ä»»åŠ¡æœ‰gapï¼‰
4. Prompt Engineeringï¼šç›´æ¥åˆ©ç”¨ä¸è®­ç»ƒè¯­è¨€æ¨¡å‹è¾…ä»¥ç‰¹å®šçš„promptã€‚ï¼ˆæœ‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä½†ä¸ä¸‹æ¸¸ä»»åŠ¡æ— gapï¼‰



## æç¤ºå­¦ä¹  prompt learning

[ã€ğŸš€èµ„æ–™ã€‘æç¤ºå­¦ä¹ æ¦‚è§ˆ](detail/NLP/æç¤ºå­¦ä¹ æ¦‚è§ˆ.md)

[ç»¼è¿°]é¹é£å¤§ç¥çš„Pre-train, Prompt, and Predict [1] - è¿·é€”å°ä¹¦åƒ®çš„æ–‡ç«  - çŸ¥ä¹ https://zhuanlan.zhihu.com/p/396098543
ã€NLPã€‘Prompt Learning è¶…å¼ºå…¥é—¨æ•™ç¨‹ - sergioçš„æ–‡ç«  - çŸ¥ä¹ https://zhuanlan.zhihu.com/p/442486331
NLP é‡Œ prompt engineering ï¼ˆè®¾è®¡ä¸€ä¸ªé—®é¢˜çš„èƒŒæ™¯æç¤ºï¼‰æœ‰å¤šé‡è¦? - çŸ¥ä¹ https://www.zhihu.com/question/439114659
ä¸€ä¸ªå°ç™½å¦‚ä½•å­¦å¥½prompt tuning? - çŸ¥ä¹ https://www.zhihu.com/question/509079916
Prompt å¦‚ä½•æ›´å¥½åœ°åº”ç”¨äºå·¥ä¸šç•Œï¼Ÿ - çŸ¥ä¹ https://www.zhihu.com/question/495040812
è¿‘ä»£è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å‘å±•çš„â€œç¬¬å››èŒƒå¼â€ - åˆ˜é¹é£çš„æ–‡ç«  - çŸ¥ä¹ https://zhuanlan.zhihu.com/p/395115779

# --ä»»åŠ¡--

## äº‹ä»¶æ¨¡å¼å½’çº³

Event Schema Induction

[äº‹ä»¶æ¨¡å¼å½’çº³ç›¸å…³ç ”ç©¶ç®€è¿°- CSDN](https://blog.csdn.net/qq_27590277/article/details/124958441)

## NER å‘½åå®ä½“è¯†åˆ«

ä»Muti-head,Biaffineåˆ°Globalpointerç»†æ•°è¿‘å¹´æ¥çš„å‘½åå®ä½“è¯†åˆ« - æˆ‘æƒ³äº†å¾ˆå¤šäº‹çš„æ–‡ç«  - çŸ¥ä¹ https://zhuanlan.zhihu.com/p/375805722

## MRC æœºå™¨é˜…è¯»ç†è§£

[ã€ğŸ¤–ï¸èµ„æ–™ã€‘MRCä¸ªäººæ€»ç»“](detail/NLP/MRCä¸ªäººæ€»ç»“.md)

## KPE å…³é”®è¯æå–

[ã€ğŸ‘“èµ„æ–™ã€‘KPEæ¦‚è§ˆ](detail/NLP/KPEæ¦‚è§ˆ.md)





# --æ–¹æ³•--

## Self-Attention è‡ªæ³¨æ„åŠ›

åœ¨Transformerçš„è®ºæ–‡ã€ŠAttention is all you needã€‹ä¸­è¢«ç†ŸçŸ¥

é€šä¿—çš„è§£é‡Šï¼šå¯¹åºåˆ—ç¼–ç è¡¨ç¤ºçš„ä¸€ä¸ªå…¨å±€ä¼˜åŒ–

> Self-Attentionçš„ä½œç”¨å°±æ˜¯å…¨å±€å…³è”æƒé‡ï¼Œç„¶ååšè¾“å…¥çš„åŠ æƒå’Œã€‚ ä¾‹å¦‚æˆ‘æœ‰ä¸‰ä¸ªè¯ A B C ï¼Œé¦–å…ˆå°†ABCç¼–ç æˆå‘é‡ï¼Œ ç„¶åè¿›Attentionå±‚ï¼Œ ç„¶åå¯¹ABCåˆ†åˆ«æ´—è„‘ï¼Œå‘Šè¯‰ä½ å…¶ä»–ä¸¤ä¸ªè¯å¯¹ä½ ä¹Ÿå¾ˆé‡è¦ï¼Œä½ çš„å¿ƒé‡Œè¦æœ‰ä»–ä»¬ï¼Œå°±è¿™æ ·æ¯ä¸ªè¯çš„é‡ç»„å°±æ˜¯ç»™è‡ªå·±ä¸€ç‚¹æƒé‡ï¼ˆæœ€å¤šï¼‰ï¼Œç»™å…¶ä»–ä¸¤ä¸ªäººä¸€ç‚¹æƒé‡ï¼Œç„¶åç»„åˆæˆæ–°çš„è‡ªå·±ã€‚https://zhuanlan.zhihu.com/p/449028081
>
> 
>
> The Annotated Transformerâ€”â€”åŸºäºPyTorchçš„å¤ç°æ³¨é‡Š
> 	https://nlp.seas.harvard.edu/2018/04/03/attention.html

## FGM æ¢¯åº¦å¯¹æŠ—

å®ç°ï¼šå¸ˆå…„çš„ç‰ˆæœ¬ï¼šhttp://192.168.126.124:9999/spico1026/ccks2022fewshotese/blob/main/src/task.py
åšå®¢ï¼šhttps://zhuanlan.zhihu.com/p/103593948
å®ç°ï¼šhttps://wmathor.com/index.php/archives/1537/

## CRF

https://github.com/Jianwei-Lv/chinese-event-extraction-pytorch
